import os
import math
from collections import Counter
from typing import List, Dict, Any, Tuple

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from googleapiclient.discovery import build
import isodate

# ============================
# ê¸°ë³¸ ì„¤ì •
# ============================

st.set_page_config(
    page_title="YouTube íŠ¸ë Œë“œÂ·ì±„ë„ ë¶„ì„ê¸° (v2.0)",
    page_icon="ğŸ“Š",
    layout="wide",
)

st.title("ğŸ“Š YouTube íŠ¸ë Œë“œÂ·ì±„ë„ ë¶„ì„ê¸° (v2.0)")
st.write("í‚¤ì›Œë“œ / ì±„ë„ ë‹¨ìœ„ë¡œ íŠ¸ë Œë“œ, íŒ¨í„´, SEO, ê²½ìŸ ë¶„ì„ê¹Œì§€ í•œ ë²ˆì— ë³´ëŠ” ëŒ€ì‹œë³´ë“œì…ë‹ˆë‹¤.")

# ============================
# ìœ í‹¸ í•¨ìˆ˜
# ============================


@st.cache_resource(show_spinner=False)
def get_youtube_client():
    """Streamlit Secrets ì—ì„œ API í‚¤ë¥¼ ì½ì–´ YouTube í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    api_key = st.secrets.get("YOUTUBE_API_KEY")
    if not api_key:
        st.error(
            "âŒ YOUTUBE_API_KEY ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\n"
            "â–¶ Streamlit Cloud â†’ App settings â†’ Secrets ì—\n"
            '   `YOUTUBE_API_KEY = "ë‹¹ì‹ ì˜_API_í‚¤"` ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'
        )
        return None
    return build("youtube", "v3", developerKey=api_key)


def parse_duration_to_minutes(duration_str: str) -> float:
    """ISO 8601 ì˜ìƒ ê¸¸ì´ ë¬¸ìì—´ì„ ë¶„ìœ¼ë¡œ ë³€í™˜"""
    try:
        duration = isodate.parse_duration(duration_str)
        return duration.total_seconds() / 60
    except Exception:
        return np.nan


def safe_int(value: Any) -> int:
    try:
        return int(value)
    except Exception:
        return 0


def extract_keywords(texts: List[str], top_n: int = 30) -> List[Tuple[str, int]]:
    """ì•„ì£¼ ë‹¨ìˆœí•œ í˜•íƒœì˜ ì˜ì–´/ìˆ«ì í‚¤ì›Œë“œ ì¶”ì¶œê¸° (í•œêµ­ì–´ëŠ” í˜•íƒœì†Œ ë¶„ì„ ì—†ì´ ë‹¨ì–´ ë‹¨ìœ„ ë¶„ë¦¬)"""
    words = []
    for t in texts:
        if not isinstance(t, str):
            continue
        # íŠ¹ìˆ˜ë¬¸ì ì œê±° & ê³µë°± ê¸°ì¤€ ë¶„ë¦¬
        for w in t.replace("\n", " ").replace("|", " ").replace(",", " ").split(" "):
            w = w.strip().lower()
            if len(w) <= 1:
                continue
            # í•´ì‹œíƒœê·¸, ê¸°í˜¸ ì œê±°
            w = w.strip("#[](){}!:;\"'")
            if not w:
                continue
            words.append(w)
    counter = Counter(words)
    return counter.most_common(top_n)


def korean_day_name(weekday: int) -> str:
    """0=ì›” ... 6=ì¼"""
    mapping = ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"]
    if 0 <= weekday <= 6:
        return mapping[weekday]
    return ""


# ============================
# YouTube API í˜¸ì¶œ í•¨ìˆ˜
# ============================


def search_videos_by_keyword(youtube, keyword: str, max_results: int = 50) -> pd.DataFrame:
    """í‚¤ì›Œë“œ ê¸°ë°˜ ì¸ê¸° ì˜ìƒ ê²€ìƒ‰ í›„ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘"""
    search_res = (
        youtube.search()
        .list(
            part="snippet",
            q=keyword,
            type="video",
            order="viewCount",
            maxResults=min(max_results, 50),
        )
        .execute()
    )

    video_ids = [item["id"]["videoId"] for item in search_res.get("items", [])]

    if not video_ids:
        return pd.DataFrame()

    video_res = (
        youtube.videos()
        .list(
            part="snippet,statistics,contentDetails",
            id=",".join(video_ids),
        )
        .execute()
    )

    rows = []
    for item in video_res.get("items", []):
        snippet = item.get("snippet", {})
        stats = item.get("statistics", {})
        content = item.get("contentDetails", {})

        duration_min = parse_duration_to_minutes(content.get("duration", "PT0M"))
        published_at = pd.to_datetime(snippet.get("publishedAt"))

        rows.append(
            {
                "ì˜ìƒID": item.get("id"),
                "ì œëª©": snippet.get("title"),
                "ì±„ë„ëª…": snippet.get("channelTitle"),
                "ì±„ë„ID": snippet.get("channelId"),
                "ì—…ë¡œë“œì¼ì‹œ": published_at,
                "ì—…ë¡œë“œì¼": published_at.date(),
                "ì—…ë¡œë“œ_ì—°ë„": published_at.year,
                "ì—…ë¡œë“œ_ì›”": published_at.month,
                "ì—…ë¡œë“œ_ìš”ì¼": korean_day_name(published_at.weekday()),
                "ì—…ë¡œë“œ_ì‹œê°": published_at.hour,
                "ì˜ìƒê¸¸ì´_ë¶„": duration_min,
                "ì¡°íšŒìˆ˜": safe_int(stats.get("viewCount")),
                "ì¢‹ì•„ìš”": safe_int(stats.get("likeCount")),
                "ëŒ“ê¸€ìˆ˜": safe_int(stats.get("commentCount")),
                "íƒœê·¸": ", ".join(snippet.get("tags", [])) if snippet.get("tags") else "",
                "ì„¤ëª…": snippet.get("description", ""),
                "ì¸ë„¤ì¼": snippet.get("thumbnails", {})
                .get("high", {})
                .get("url", ""),
            }
        )

    df = pd.DataFrame(rows)
    if not df.empty:
        df.sort_values("ì¡°íšŒìˆ˜", ascending=False, inplace=True)
        df.reset_index(drop=True, inplace=True)

    return df


def search_channels(youtube, keyword: str, max_results: int = 10) -> pd.DataFrame:
    """í‚¤ì›Œë“œë¡œ ì±„ë„ ê²€ìƒ‰"""
    res = (
        youtube.search()
        .list(
            part="snippet",
            q=keyword,
            type="channel",
            maxResults=max_results,
        )
        .execute()
    )

    rows = []
    for item in res.get("items", []):
        snippet = item.get("snippet", {})
        rows.append(
            {
                "ì±„ë„ëª…": snippet.get("title"),
                "ì±„ë„ID": item["id"]["channelId"],
                "ì„¤ëª…": snippet.get("description"),
            }
        )
    return pd.DataFrame(rows)


def fetch_channel_basic_info(youtube, channel_id: str) -> Dict[str, Any]:
    """ì±„ë„ ê¸°ë³¸ ì •ë³´"""
    res = (
        youtube.channels()
        .list(
            part="snippet,statistics",
            id=channel_id,
        )
        .execute()
    )
    items = res.get("items", [])
    if not items:
        return {}
    item = items[0]
    snippet = item.get("snippet", {})
    stats = item.get("statistics", {})
    return {
        "ì±„ë„ëª…": snippet.get("title"),
        "ì„¤ëª…": snippet.get("description"),
        "êµ¬ë…ì": safe_int(stats.get("subscriberCount")),
        "ì´ì¡°íšŒìˆ˜": safe_int(stats.get("viewCount")),
        "ì˜ìƒìˆ˜": safe_int(stats.get("videoCount")),
        "ìƒì„±ì¼": snippet.get("publishedAt"),
    }


def fetch_channel_videos(youtube, channel_id: str, max_results: int = 120) -> pd.DataFrame:
    """
    ì±„ë„ì˜ ìµœê·¼ ì˜ìƒë“¤ ì •ë³´ë¥¼ ê°€ì ¸ì˜¨ë‹¤.
    ì‹¤ì œë¡œëŠ” playlistItems APIë¡œ 'uploads' ì¬ìƒëª©ë¡ì—ì„œ ê°€ì ¸ì˜¤ëŠ” ê²Œ ë” ì •í™•í•˜ì§€ë§Œ,
    ì—¬ê¸°ì„œëŠ” search.list ë¡œ ê°„ë‹¨íˆ êµ¬í˜„ (ìµœê·¼ ì˜ìƒ ê¸°ì¤€)
    """
    search_res = (
        youtube.search()
        .list(
            part="snippet",
            channelId=channel_id,
            type="video",
            order="date",
            maxResults=min(max_results, 50),
        )
        .execute()
    )

    video_ids = [item["id"]["videoId"] for item in search_res.get("items", [])]
    if not video_ids:
        return pd.DataFrame()

    video_res = (
        youtube.videos()
        .list(
            part="snippet,statistics,contentDetails",
            id=",".join(video_ids),
        )
        .execute()
    )

    rows = []
    for item in video_res.get("items", []):
        snippet = item.get("snippet", {})
        stats = item.get("statistics", {})
        content = item.get("contentDetails", {})

        published_at = pd.to_datetime(snippet.get("publishedAt"))
        duration_min = parse_duration_to_minutes(content.get("duration", "PT0M"))

        rows.append(
            {
                "ì˜ìƒID": item.get("id"),
                "ì œëª©": snippet.get("title"),
                "ì—…ë¡œë“œì¼ì‹œ": published_at,
                "ì—…ë¡œë“œì¼": published_at.date(),
                "ì—…ë¡œë“œ_ì—°ë„": published_at.year,
                "ì—…ë¡œë“œ_ì›”": published_at.month,
                "ì—…ë¡œë“œ_ìš”ì¼": korean_day_name(published_at.weekday()),
                "ì—…ë¡œë“œ_ì‹œê°": published_at.hour,
                "ì˜ìƒê¸¸ì´_ë¶„": duration_min,
                "ì¡°íšŒìˆ˜": safe_int(stats.get("viewCount")),
                "ì¢‹ì•„ìš”": safe_int(stats.get("likeCount")),
                "ëŒ“ê¸€ìˆ˜": safe_int(stats.get("commentCount")),
                "íƒœê·¸": ", ".join(snippet.get("tags", [])) if snippet.get("tags") else "",
                "ì„¤ëª…": snippet.get("description", ""),
                "ì¸ë„¤ì¼": snippet.get("thumbnails", {})
                .get("high", {})
                .get("url", ""),
            }
        )

    df = pd.DataFrame(rows)
    if not df.empty:
        df.sort_values("ì—…ë¡œë“œì¼ì‹œ", ascending=False, inplace=True)
        df.reset_index(drop=True, inplace=True)
    return df


# ============================
# ë¶„ì„ í•¨ìˆ˜ë“¤
# ============================


def summarize_basic_stats(df: pd.DataFrame) -> Dict[str, Any]:
    """ì˜ìƒ ë°ì´í„° ê¸°ë³¸ í†µê³„"""
    if df.empty:
        return {}
    return {
        "ì˜ìƒìˆ˜": len(df),
        "í‰ê· ì¡°íšŒìˆ˜": round(df["ì¡°íšŒìˆ˜"].mean()),
        "ì¤‘ê°„ê°’ì¡°íšŒìˆ˜": int(df["ì¡°íšŒìˆ˜"].median()),
        "ìµœê³ ì¡°íšŒìˆ˜": int(df["ì¡°íšŒìˆ˜"].max()),
        "í‰ê· ì¢‹ì•„ìš”": round(df["ì¢‹ì•„ìš”"].mean()),
        "í‰ê· ëŒ“ê¸€": round(df["ëŒ“ê¸€ìˆ˜"].mean()),
        "í‰ê· ì˜ìƒê¸¸ì´(ë¶„)": round(df["ì˜ìƒê¸¸ì´_ë¶„"].mean(), 1),
    }


def recommend_best_upload_times(df: pd.DataFrame) -> pd.DataFrame:
    """
    ìš”ì¼/ì‹œê°„ëŒ€ë³„ í‰ê·  ì¡°íšŒìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ
    'ì¶”ì²œ ì—…ë¡œë“œ ì‹œê°„ëŒ€'ë¥¼ ë½‘ëŠ”ë‹¤.
    """
    if df.empty:
        return pd.DataFrame()

    # ì‹œê°„ëŒ€ë¥¼ 4êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ”
    def bucket_hour(h):
        if 6 <= h < 12:
            return "ì•„ì¹¨(06-12)"
        elif 12 <= h < 18:
            return "ë‚®(12-18)"
        elif 18 <= h < 24:
            return "ì €ë…(18-24)"
        else:
            return "ì‹¬ì•¼(00-06)"

    temp = df.copy()
    temp["ì‹œê°„ëŒ€êµ¬ê°„"] = temp["ì—…ë¡œë“œ_ì‹œê°"].apply(bucket_hour)
    grp = temp.groupby(["ì—…ë¡œë“œ_ìš”ì¼", "ì‹œê°„ëŒ€êµ¬ê°„"])["ì¡°íšŒìˆ˜"].mean().reset_index()
    grp.rename(columns={"ì¡°íšŒìˆ˜": "í‰ê· ì¡°íšŒìˆ˜"}, inplace=True)
    grp.sort_values("í‰ê· ì¡°íšŒìˆ˜", ascending=False, inplace=True)
    return grp


def generate_content_ideas(keyword: str, df: pd.DataFrame) -> List[str]:
    """ê°„ë‹¨ ê·œì¹™ ê¸°ë°˜ ì½˜í…ì¸  ê¸°íš ì•„ì´ë””ì–´"""
    ideas = []
    base = keyword.strip()
    if not base:
        base = "ë‹¹ì‹ ì˜ ì£¼ì œ"

    ideas.append(f"ğŸ“Œ {base} ê´€ë ¨ 'ì‹¤ì œ ì‚¬ë¡€Â·ì°' í˜•ì‹ì˜ ìŠ¤í† ë¦¬í…”ë§ ì˜ìƒ")
    ideas.append(f"ğŸ“Œ '{base}' ì˜ëª»ëœ ìƒì‹ TOP5 / í”í•œ ì‹¤ìˆ˜ ì •ë¦¬ ì˜ìƒ")
    ideas.append(f"ğŸ“Œ êµ¬ë…ì Q&A: '{base}'ì— ëŒ€í•´ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ ëª¨ì•„ì„œ ë‹µë³€")
    ideas.append(f"ğŸ“Œ '{base}' ì´ˆë³´ììš© ì…ë¬¸ ê°€ì´ë“œ (ì™„ì „ ê¸°ì´ˆë¶€í„° ì•Œë ¤ì£¼ê¸°)")
    ideas.append(f"ğŸ“Œ '{base}' ìµœì‹  íŠ¸ë Œë“œì™€ ê³¼ê±° ë¹„êµ (ì „/í›„ ë³€í™” ë¶„ì„)")
    if not df.empty:
        short_ones = df.sort_values("ì˜ìƒê¸¸ì´_ë¶„").head(10)
        if not short_ones.empty:
            ideas.append(
                "ğŸ“Œ ì¡°íšŒìˆ˜ ì˜ ë‚˜ì˜¨ 'ì§§ì€ ì˜ìƒ' í¬ë§·ì„ í™œìš©í•´ì„œ Shorts ì‹œë¦¬ì¦ˆ ë§Œë“¤ì–´ë³´ê¸°"
            )
        high_like = df.sort_values("ì¢‹ì•„ìš”", ascending=False).head(5)
        if not high_like.empty:
            ideas.append(
                "ğŸ“Œ ì¢‹ì•„ìš” ë¹„ìœ¨ ë†’ì€ ì˜ìƒë“¤ì˜ ê³µí†µ í¬ë§·(ì œëª© êµ¬ì¡°/ì¸ë„¤ì¼ ìŠ¤íƒ€ì¼)ì„ ë”°ë¼ê°€ëŠ” ì‹œë¦¬ì¦ˆ"
            )
    return ideas


def generate_title_tag_templates(keyword: str, top_keywords: List[Tuple[str, int]]) -> Dict[str, List[str]]:
    """ê°„ë‹¨ ì œëª©/íƒœê·¸ í…œí”Œë¦¿"""
    core = keyword.strip()
    if not core and top_keywords:
        core = top_keywords[0][0]
    if not core:
        core = "ì´ ì£¼ì œ"

    title_templates = [
        f"{core} ë•ë¶„ì— ì¸ìƒì´ ë°”ë€ ì´ì•¼ê¸°",
        f"ì•„ë¬´ë„ ì•ˆ ì•Œë ¤ì£¼ëŠ” {core} í˜„ì‹¤ ì¡°ì–¸",
        f"ì²˜ìŒë¶€í„° ë‹¤ì‹œ ë°°ìš°ëŠ” {core} (ì™„ì „ ê¸°ì´ˆí¸)",
        f"{core} í•  ë•Œ ê¼­ ì•Œì•„ì•¼ í•˜ëŠ” 5ê°€ì§€",
        f"ìš”ì¦˜ ë‹¤ë“¤ í•˜ëŠ” {core}, í•˜ì§€ë§Œ ì—¬ëŸ¬ë¶„ì´ ëª¨ë¥´ëŠ” ì§„ì‹¤",
    ]

    # íƒœê·¸: í‚¤ì›Œë“œ + ìƒìœ„ ë‹¨ì–´ë“¤ ì¡°í•©
    tags = [core]
    for w, _ in top_keywords[:15]:
        if w not in tags:
            tags.append(w)

    return {"titles": title_templates, "tags": tags}


# ============================
# ë©”ì¸ UI
# ============================

youtube = get_youtube_client()

with st.sidebar:
    st.header("âš™ï¸ ë¶„ì„ ëª¨ë“œ ì„ íƒ")
    mode = st.radio(
        "ë¶„ì„ ëŒ€ìƒ",
        ["í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¶„ì„", "íŠ¹ì • ì±„ë„ ë¶„ì„", "ê²½ìŸ ì±„ë„ ë²¤ì¹˜ë§ˆí‚¹"],
    )

    max_results = st.slider("ê°€ì ¸ì˜¬ ì˜ìƒ ê°œìˆ˜ (ëŒ€ëµ)", 20, 150, 60, 10)
    st.caption("â€» ë„ˆë¬´ ë§ì´ ê°€ì ¸ì˜¤ë©´ YouTube API ì¿¼í„°ë¥¼ ë¹¨ë¦¬ ì†Œëª¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

if youtube is None:
    st.stop()

# -----------------------------
# 1) í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¶„ì„
# -----------------------------
if mode == "í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¶„ì„":
    keyword = st.text_input("ğŸ” ë¶„ì„í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì‹œë‹ˆì–´ ì‡¼í•‘, ê±´ê°•, ìš”ë¦¬)", value="")
    if not keyword:
        st.info("ì¢Œì¸¡ ì‚¬ì´ë“œë°” ì„¤ì • í›„, í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ë©´ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        st.stop()

    with st.spinner("YouTubeì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
        df = search_videos_by_keyword(youtube, keyword, max_results=max_results)

    if df.empty:
        st.warning("í•´ë‹¹ í‚¤ì›Œë“œë¡œ ì˜ìƒ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        st.stop()

    st.subheader(f"ğŸ¬ '{keyword}' í‚¤ì›Œë“œ ì¸ê¸° ì˜ìƒ ë°ì´í„° ({len(df)}ê°œ)")
    st.dataframe(
        df[
            [
                "ì œëª©",
                "ì±„ë„ëª…",
                "ì¡°íšŒìˆ˜",
                "ì¢‹ì•„ìš”",
                "ëŒ“ê¸€ìˆ˜",
                "ì˜ìƒê¸¸ì´_ë¶„",
                "ì—…ë¡œë“œì¼",
                "ì—…ë¡œë“œ_ìš”ì¼",
                "ì—…ë¡œë“œ_ì‹œê°",
            ]
        ],
        use_container_width=True,
    )

    # ê¸°ë³¸ í†µê³„ ì¹´ë“œ
    stats = summarize_basic_stats(df)
    if stats:
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("ì˜ìƒìˆ˜", f"{stats['ì˜ìƒìˆ˜']}ê°œ")
        c2.metric("í‰ê·  ì¡°íšŒìˆ˜", f"{stats['í‰ê· ì¡°íšŒìˆ˜']:,}")
        c3.metric("ì¤‘ê°„ê°’ ì¡°íšŒìˆ˜", f"{stats['ì¤‘ê°„ê°’ì¡°íšŒìˆ˜']:,}")
        c4.metric("ìµœê³  ì¡°íšŒìˆ˜", f"{stats['ìµœê³ ì¡°íšŒìˆ˜']:,}")

    # ê·¸ë˜í”„ë“¤
    st.markdown("### ğŸ“ˆ ì¡°íšŒìˆ˜ ë¶„í¬")

    fig_hist = px.histogram(df, x="ì¡°íšŒìˆ˜", nbins=20, title="ì¡°íšŒìˆ˜ ë¶„í¬")
    st.plotly_chart(fig_hist, use_container_width=True)

    st.markdown("### â± ì˜ìƒ ê¸¸ì´ vs ì¡°íšŒìˆ˜")
    fig_len = px.scatter(
        df,
        x="ì˜ìƒê¸¸ì´_ë¶„",
        y="ì¡°íšŒìˆ˜",
        hover_data=["ì œëª©", "ì±„ë„ëª…"],
        trendline="ols",
        title="ì˜ìƒ ê¸¸ì´(ë¶„) vs ì¡°íšŒìˆ˜",
    )
    st.plotly_chart(fig_len, use_container_width=True)

    st.markdown("### ğŸ“† ìš”ì¼Â·ì‹œê°„ëŒ€ë³„ ì—…ë¡œë“œ íŒ¨í„´")

    # ìš”ì¼ë³„ ì˜ìƒ ìˆ˜
    fig_dow = px.histogram(
        df,
        x="ì—…ë¡œë“œ_ìš”ì¼",
        title="ìš”ì¼ë³„ ì—…ë¡œë“œ ì˜ìƒ ìˆ˜",
    )
    st.plotly_chart(fig_dow, use_container_width=True)

    # ì‹œê°„ëŒ€ íˆìŠ¤í† ê·¸ë¨
    fig_hour = px.histogram(
        df,
        x="ì—…ë¡œë“œ_ì‹œê°",
        title="ì‹œê°„ëŒ€ë³„ ì—…ë¡œë“œ ì˜ìƒ ìˆ˜",
    )
    st.plotly_chart(fig_hour, use_container_width=True)

    # í‚¤ì›Œë“œ/íƒœê·¸ ë¶„ì„
    st.markdown("### ğŸ” ì œëª©/íƒœê·¸ í‚¤ì›Œë“œ ë¶„ì„")

    title_keywords = extract_keywords(df["ì œëª©"].tolist(), top_n=30)
    tag_keywords = extract_keywords(df["íƒœê·¸"].tolist(), top_n=30)

    col1, col2 = st.columns(2)
    with col1:
        st.write("**ì œëª©ì—ì„œ ìì£¼ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ Top 30**")
        st.table(pd.DataFrame(title_keywords, columns=["ë‹¨ì–´", "ë¹ˆë„"]))
    with col2:
        st.write("**íƒœê·¸ì—ì„œ ìì£¼ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ Top 30**")
        st.table(pd.DataFrame(tag_keywords, columns=["ë‹¨ì–´", "ë¹ˆë„"]))

    # ì œëª©/íƒœê·¸ í…œí”Œë¦¿ + ì½˜í…ì¸  ì•„ì´ë””ì–´
    st.markdown("### ğŸ§  ì½˜í…ì¸  ê¸°íš & SEO ë„ì›€")

    templates = generate_title_tag_templates(keyword, title_keywords or tag_keywords)
    ideas = generate_content_ideas(keyword, df)

    c1, c2 = st.columns(2)
    with c1:
        st.write("**ì¶”ì²œ ì œëª© í…œí”Œë¦¿**")
        for t in templates["titles"]:
            st.write("- ", t)
    with c2:
        st.write("**ì¶”ì²œ íƒœê·¸ í›„ë³´**")
        st.write(", ".join(templates["tags"]))

    st.write("**í–¥í›„ ì½˜í…ì¸  ê¸°íš ì•„ì´ë””ì–´**")
    for idea in ideas:
        st.write(idea)

    # CSV ë‹¤ìš´ë¡œë“œ
    csv = df.to_csv(index=False).encode("utf-8-sig")
    st.download_button(
        "â¬‡ï¸ ì´ í‚¤ì›Œë“œ ì˜ìƒ ë°ì´í„° CSV ë‹¤ìš´ë¡œë“œ",
        csv,
        file_name=f"youtube_keyword_{keyword}.csv",
        mime="text/csv",
    )

# -----------------------------
# 2) íŠ¹ì • ì±„ë„ ë¶„ì„
# -----------------------------
elif mode == "íŠ¹ì • ì±„ë„ ë¶„ì„":
    st.markdown("### ğŸ” ì±„ë„ ê²€ìƒ‰ ë˜ëŠ” ì±„ë„ID ì§ì ‘ ì…ë ¥")

    tab1, tab2 = st.tabs(["ì±„ë„ ê²€ìƒ‰", "ì±„ë„ ID ì§ì ‘ ì…ë ¥"])

    channel_id = None
    channel_keyword = None

    with tab1:
        channel_keyword = st.text_input(
            "ì±„ë„ì„ ê²€ìƒ‰í•  í‚¤ì›Œë“œ (ì±„ë„ëª… / ì£¼ì œ ë“±)",
            value="",
        )
        if channel_keyword:
            if st.button("ì±„ë„ ê²€ìƒ‰í•˜ê¸°"):
                with st.spinner("ì±„ë„ì„ ê²€ìƒ‰í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                    ch_df = search_channels(youtube, channel_keyword, max_results=15)
                if ch_df.empty:
                    st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.write("ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ë¶„ì„í•  ì±„ë„ì„ ì„ íƒí•˜ì„¸ìš”.")
                    selected = st.selectbox(
                        "ì±„ë„ ì„ íƒ", [f"{r['ì±„ë„ëª…']} ({r['ì±„ë„ID']})" for _, r in ch_df.iterrows()]
                    )
                    if selected:
                        channel_id = selected.split("(")[-1].replace(")", "").strip()

    with tab2:
        manual_id = st.text_input("YouTube ì±„ë„ ID ì§ì ‘ ì…ë ¥", value="")
        if manual_id:
            channel_id = manual_id.strip()

    if not channel_id:
        st.info("ì±„ë„ì„ ì„ íƒí•˜ê±°ë‚˜ ì±„ë„ IDë¥¼ ì…ë ¥í•˜ë©´ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        st.stop()

    with st.spinner("ì±„ë„ ê¸°ë³¸ ì •ë³´ì™€ ì˜ìƒ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
        basic = fetch_channel_basic_info(youtube, channel_id)
        df = fetch_channel_videos(youtube, channel_id, max_results=max_results)

    if not basic:
        st.error("ì±„ë„ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì±„ë„ IDë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    st.subheader(f"ğŸ“º ì±„ë„ ì •ë³´: {basic['ì±„ë„ëª…']}")
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("êµ¬ë…ì", f"{basic['êµ¬ë…ì']:,}")
    col2.metric("ì´ ì¡°íšŒìˆ˜", f"{basic['ì´ì¡°íšŒìˆ˜']:,}")
    col3.metric("ì˜ìƒ ìˆ˜(ì „ì²´)", f"{basic['ì˜ìƒìˆ˜']:,}")
    col4.metric("ë¶„ì„ ì˜ìƒ ìˆ˜(ìµœê·¼)", f"{len(df)}ê°œ")

    st.write("**ì±„ë„ ì„¤ëª…**")
    st.write(basic.get("ì„¤ëª…") or "(ì„¤ëª… ì—†ìŒ)")

    if df.empty:
        st.warning("ì´ ì±„ë„ì—ì„œ ìµœê·¼ ì˜ìƒì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        st.stop()

    st.markdown("### ğŸ¬ ìµœê·¼ ì˜ìƒ ë°ì´í„°")
    st.dataframe(
        df[
            [
                "ì œëª©",
                "ì¡°íšŒìˆ˜",
                "ì¢‹ì•„ìš”",
                "ëŒ“ê¸€ìˆ˜",
                "ì˜ìƒê¸¸ì´_ë¶„",
                "ì—…ë¡œë“œì¼",
                "ì—…ë¡œë“œ_ìš”ì¼",
                "ì—…ë¡œë“œ_ì‹œê°",
            ]
        ],
        use_container_width=True,
    )

    stats = summarize_basic_stats(df)
    if stats:
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("í‰ê·  ì¡°íšŒìˆ˜", f"{stats['í‰ê· ì¡°íšŒìˆ˜']:,}")
        c2.metric("ì¤‘ê°„ê°’ ì¡°íšŒìˆ˜", f"{stats['ì¤‘ê°„ê°’ì¡°íšŒìˆ˜']:,}")
        c3.metric("í‰ê·  ì¢‹ì•„ìš”", f"{stats['í‰ê· ì¢‹ì•„ìš”']:,}")
        c4.metric("í‰ê·  ì˜ìƒ ê¸¸ì´(ë¶„)", f"{stats['í‰ê· ì˜ìƒê¸¸ì´(ë¶„)']}")

    # ì¸ê¸° ì˜ìƒ TOP 10
    st.markdown("### ğŸ”¥ ì¸ê¸° ì˜ìƒ TOP 10")
    top_videos = df.sort_values("ì¡°íšŒìˆ˜", ascending=False).head(10)[
        ["ì œëª©", "ì¡°íšŒìˆ˜", "ì¢‹ì•„ìš”", "ëŒ“ê¸€ìˆ˜", "ì˜ìƒê¸¸ì´_ë¶„", "ì—…ë¡œë“œì¼"]
    ]
    st.table(top_videos)

    # ì—…ë¡œë“œ íŒ¨í„´ ë¶„ì„
    st.markdown("### ğŸ“† ì—…ë¡œë“œ íŒ¨í„´ ë¶„ì„ (ìš”ì¼ / ì‹œê°„ëŒ€)")

    fig_dow = px.histogram(
        df,
        x="ì—…ë¡œë“œ_ìš”ì¼",
        title="ìš”ì¼ë³„ ì—…ë¡œë“œ ì˜ìƒ ìˆ˜",
    )
    st.plotly_chart(fig_dow, use_container_width=True)

    fig_hour = px.histogram(
        df,
        x="ì—…ë¡œë“œ_ì‹œê°",
        title="ì‹œê°„ëŒ€ë³„ ì—…ë¡œë“œ ì˜ìƒ ìˆ˜",
    )
    st.plotly_chart(fig_hour, use_container_width=True)

    # ìš”ì¼/ì‹œê°„ëŒ€ë³„ í‰ê·  ì¡°íšŒìˆ˜ íˆíŠ¸ë§µ
    temp = df.copy()
    if not temp.empty:
        pivot = (
            temp.groupby(["ì—…ë¡œë“œ_ìš”ì¼", "ì—…ë¡œë“œ_ì‹œê°"])["ì¡°íšŒìˆ˜"]
            .mean()
            .reset_index()
        )
        heat = pivot.pivot(index="ì—…ë¡œë“œ_ìš”ì¼", columns="ì—…ë¡œë“œ_ì‹œê°", values="ì¡°íšŒìˆ˜")
        fig_heat = px.imshow(
            heat,
            aspect="auto",
            color_continuous_scale="Blues",
            labels=dict(color="í‰ê·  ì¡°íšŒìˆ˜"),
            title="ìš”ì¼ / ì‹œê°„ëŒ€ë³„ í‰ê·  ì¡°íšŒìˆ˜ íˆíŠ¸ë§µ",
        )
        st.plotly_chart(fig_heat, use_container_width=True)

    # ì¶”ì²œ ì—…ë¡œë“œ ì‹œê°„
    st.markdown("### â° ì¶”ì²œ ì—…ë¡œë“œ ì‹œê°„ëŒ€")
    best_times = recommend_best_upload_times(df)
    if not best_times.empty:
        st.write("í‰ê·  ì¡°íšŒìˆ˜ ìƒìœ„ 10ê°œ ì‹œê°„ëŒ€:")
        st.table(best_times.head(10))
    else:
        st.write("ì¶”ì²œ ì‹œê°„ëŒ€ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

    # ì œëª©/íƒœê·¸ í‚¤ì›Œë“œ ë¶„ì„ + ê¸°íš ì•„ì´ë””ì–´
    st.markdown("### ğŸ” ì œëª©/íƒœê·¸ ë¶„ì„ ë° ì½˜í…ì¸  ì•„ì´ë””ì–´")

    title_keywords = extract_keywords(df["ì œëª©"].tolist(), top_n=30)
    tag_keywords = extract_keywords(df["íƒœê·¸"].tolist(), top_n=30)

    col1, col2 = st.columns(2)
    with col1:
        st.write("**ì œëª©ì—ì„œ ìì£¼ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ Top 30**")
        st.table(pd.DataFrame(title_keywords, columns=["ë‹¨ì–´", "ë¹ˆë„"]))
    with col2:
        st.write("**íƒœê·¸ì—ì„œ ìì£¼ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ Top 30**")
        st.table(pd.DataFrame(tag_keywords, columns=["ë‹¨ì–´", "ë¹ˆë„"]))

    templates = generate_title_tag_templates(
        basic["ì±„ë„ëª…"], title_keywords or tag_keywords
    )
    ideas = generate_content_ideas(basic["ì±„ë„ëª…"], df)

    c1, c2 = st.columns(2)
    with c1:
        st.write("**ì´ ì±„ë„ì— ì–´ìš¸ë¦¬ëŠ” ì œëª© í…œí”Œë¦¿**")
        for t in templates["titles"]:
            st.write("- ", t)
    with c2:
        st.write("**ì¶”ì²œ íƒœê·¸ í›„ë³´**")
        st.write(", ".join(templates["tags"]))

    st.write("**í–¥í›„ ì½˜í…ì¸  ê¸°íš ì•„ì´ë””ì–´**")
    for idea in ideas:
        st.write(idea)

    csv = df.to_csv(index=False).encode("utf-8-sig")
    st.download_button(
        "â¬‡ï¸ ì´ ì±„ë„ ìµœê·¼ ì˜ìƒ ë°ì´í„° CSV ë‹¤ìš´ë¡œë“œ",
        csv,
        file_name=f"youtube_channel_{basic['ì±„ë„ëª…']}.csv",
        mime="text/csv",
    )

# -----------------------------
# 3) ê²½ìŸ ì±„ë„ ë²¤ì¹˜ë§ˆí‚¹
# -----------------------------
elif mode == "ê²½ìŸ ì±„ë„ ë²¤ì¹˜ë§ˆí‚¹":
    st.markdown("### ğŸ¥Š ê²½ìŸ ì±„ë„ ë²¤ì¹˜ë§ˆí‚¹ (ê°„ë‹¨ ë²„ì „)")

    keyword = st.text_input(
        "ê²½ìŸ ì±„ë„ì„ ì°¾ì„ í‚¤ì›Œë“œ (ì˜ˆ: 'ì‹œë‹ˆì–´ ë“œë¼ë§ˆ', 'ë¶€ë™ì‚° íˆ¬ì', 'ë‹¤ì´ì–´íŠ¸')",
        value="",
    )
    if not keyword:
        st.info("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ë©´ ê´€ë ¨ ì±„ë„ë“¤ì„ ì°¾ì•„ì„œ ë¹„êµí•©ë‹ˆë‹¤.")
        st.stop()

    with st.spinner("ê²½ìŸ ì±„ë„ í›„ë³´ë¥¼ ì°¾ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
        ch_df = search_channels(youtube, keyword, max_results=8)

    if ch_df.empty:
        st.warning("ê´€ë ¨ ì±„ë„ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        st.stop()

    st.write("**ê´€ë ¨ ì±„ë„ í›„ë³´**")
    st.table(ch_df[["ì±„ë„ëª…", "ì±„ë„ID", "ì„¤ëª…"]])

    selected_ids = st.multiselect(
        "ë²¤ì¹˜ë§ˆí‚¹í•  ì±„ë„ 2~5ê°œë¥¼ ì„ íƒí•˜ì„¸ìš”.",
        options=ch_df["ì±„ë„ID"].tolist(),
        default=ch_df["ì±„ë„ID"].tolist()[:3],
        format_func=lambda cid: ch_df[ch_df["ì±„ë„ID"] == cid]["ì±„ë„ëª…"].iloc[0],
    )

    if len(selected_ids) < 2:
        st.info("ë‘ ê°œ ì´ìƒ ì„ íƒí•´ì•¼ ë¹„êµê°€ ì˜ë¯¸ ìˆìŠµë‹ˆë‹¤.")
        st.stop()

    results = []
    with st.spinner("ì„ íƒí•œ ì±„ë„ì˜ ê¸°ë³¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
        for cid in selected_ids:
            info = fetch_channel_basic_info(youtube, cid)
            if not info:
                continue
            info["ì±„ë„ID"] = cid
            results.append(info)

    if not results:
        st.error("ì„ íƒí•œ ì±„ë„ë“¤ì˜ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        st.stop()

    bench_df = pd.DataFrame(results)[
        ["ì±„ë„ëª…", "ì±„ë„ID", "êµ¬ë…ì", "ì´ì¡°íšŒìˆ˜", "ì˜ìƒìˆ˜"]
    ]
    st.subheader("ğŸ“Š ê²½ìŸ ì±„ë„ ê¸°ë³¸ ì§€í‘œ ë¹„êµ")
    st.dataframe(bench_df, use_container_width=True)

    fig_sub = px.bar(
        bench_df,
        x="ì±„ë„ëª…",
        y="êµ¬ë…ì",
        title="ì±„ë„ë³„ êµ¬ë…ì ìˆ˜ ë¹„êµ",
        text="êµ¬ë…ì",
    )
    st.plotly_chart(fig_sub, use_container_width=True)

    fig_view = px.bar(
        bench_df,
        x="ì±„ë„ëª…",
        y="ì´ì¡°íšŒìˆ˜",
        title="ì±„ë„ë³„ ì´ ì¡°íšŒìˆ˜ ë¹„êµ",
        text="ì´ì¡°íšŒìˆ˜",
    )
    st.plotly_chart(fig_view, use_container_width=True)

    st.markdown("### ğŸ§¾ ìš”ì•½ ì½”ë©˜íŠ¸ (ê·œì¹™ ê¸°ë°˜)")

    # ì•„ì£¼ ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ìš”ì•½
    top_sub = bench_df.sort_values("êµ¬ë…ì", ascending=False).iloc[0]
    top_view = bench_df.sort_values("ì´ì¡°íšŒìˆ˜", ascending=False).iloc[0]
    top_prod = bench_df.sort_values("ì˜ìƒìˆ˜", ascending=False).iloc[0]

    st.write(
        f"- **êµ¬ë…ì ê¸°ì¤€ 1ìœ„ ì±„ë„**: {top_sub['ì±„ë„ëª…']} (êµ¬ë…ì {top_sub['êµ¬ë…ì']:,}ëª…)"
    )
    st.write(
        f"- **ì´ ì¡°íšŒìˆ˜ ê¸°ì¤€ 1ìœ„ ì±„ë„**: {top_view['ì±„ë„ëª…']} (ì´ ì¡°íšŒìˆ˜ {top_view['ì´ì¡°íšŒìˆ˜']:,}íšŒ)"
    )
    st.write(
        f"- **ì˜ìƒ ìƒì‚°ëŸ‰(ì˜ìƒ ìˆ˜) ê¸°ì¤€ 1ìœ„ ì±„ë„**: {top_prod['ì±„ë„ëª…']} (ì˜ìƒ {top_prod['ì˜ìƒìˆ˜']:,}ê°œ)"
    )
    st.write(
        "- êµ¬ë…ì ëŒ€ë¹„ ì¡°íšŒìˆ˜ ë¹„ìœ¨ì´ ë†’ì€ ì±„ë„ì€ **ì¶©ì„±ë„ê°€ ë†’ì€ ì‹œì²­ìì¸µ**ì„ ê°–ê³  ìˆì„ ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤.\n"
        "  â†’ ì´ ì±„ë„ë“¤ì˜ ì œëª© êµ¬ì¡°, ì¸ë„¤ì¼ ìŠ¤íƒ€ì¼, ì—…ë¡œë“œ ë¹ˆë„ë¥¼ ì§‘ì¤‘ì ìœ¼ë¡œ ì°¸ê³ í•´ë³´ì„¸ìš”."
    )
