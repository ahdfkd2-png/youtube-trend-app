import streamlit as st
import pandas as pd
import math
import re
from datetime import datetime
from collections import Counter

from googleapiclient.discovery import build
from googleapiclient.errors import HttpError


# -----------------------------
# ê¸°ë³¸ ì„¤ì •
# -----------------------------
st.set_page_config(
    page_title="YouTube íŠ¸ë Œë“œÂ·ì±„ë„ ë¶„ì„ê¸°",
    layout="wide",
)

st.title("ğŸ“Š YouTube íŠ¸ë Œë“œÂ·ì±„ë„ ë¶„ì„ê¸° (v2.0)")
st.caption("í‚¤ì›Œë“œ / ì±„ë„ ê¸°ë°˜ìœ¼ë¡œ ì˜ìƒ ì„±ê³¼ì™€ íŒ¨í„´ì„ ë¶„ì„í•´ì£¼ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.")


# -----------------------------
# YouTube API ìœ í‹¸ í•¨ìˆ˜
# -----------------------------
@st.cache_resource(show_spinner=False)
def get_youtube_client():
    api_key = st.secrets.get("YOUTUBE_API_KEY")
    if not api_key:
        st.error(
            "âŒ YOUTUBE_API_KEY ì‹œí¬ë¦¿ì´ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\n"
            "Streamlit Cloud > App settings > Secrets ì—ì„œ `YOUTUBE_API_KEY=\"...\"` ë¥¼ ì¶”ê°€í•´ ì£¼ì„¸ìš”."
        )
        st.stop()
    return build("youtube", "v3", developerKey=api_key)


def parse_int(value):
    try:
        return int(value)
    except Exception:
        return 0


def parse_duration_to_minutes(iso_duration: str) -> float:
    """
    ISO 8601 í˜•ì‹ì˜ duration (ì˜ˆ: PT12M30S)ì„ ë¶„ ë‹¨ìœ„(float)ë¡œ ë³€í™˜
    """
    if not iso_duration:
        return 0.0

    pattern = r"PT(?:(\d+)H)?(?:(\d+)M)?(?:(\d+)S)?"
    m = re.match(pattern, iso_duration)
    if not m:
        return 0.0

    hours = int(m.group(1)) if m.group(1) else 0
    minutes = int(m.group(2)) if m.group(2) else 0
    seconds = int(m.group(3)) if m.group(3) else 0

    total_minutes = hours * 60 + minutes + seconds / 60
    return total_minutes


# -----------------------------
# ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ë“¤
# -----------------------------
@st.cache_data(show_spinner="ğŸ” ì˜ìƒ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
def search_videos(keyword: str, max_results: int = 20):
    youtube = get_youtube_client()

    try:
        search_response = youtube.search().list(
            part="snippet",
            q=keyword,
            type="video",
            order="relevance",
            maxResults=max_results,
        ).execute()
    except HttpError as e:
        st.error(f"ìœ íŠœë¸Œ API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return pd.DataFrame()

    video_items = search_response.get("items", [])
    video_ids = [item["id"]["videoId"] for item in video_items]

    if not video_ids:
        return pd.DataFrame()

    videos_response = youtube.videos().list(
        part="snippet,statistics,contentDetails",
        id=",".join(video_ids),
    ).execute()

    rows = []
    for item in videos_response.get("items", []):
        snippet = item.get("snippet", {})
        stats = item.get("statistics", {})
        content = item.get("contentDetails", {})

        published_at_str = snippet.get("publishedAt")
        try:
            published_at = datetime.fromisoformat(
                published_at_str.replace("Z", "+00:00")
            )
        except Exception:
            published_at = None

        duration_minutes = parse_duration_to_minutes(content.get("duration"))

        rows.append(
            {
                "video_id": item.get("id"),
                "ì œëª©": snippet.get("title"),
                "ì±„ë„ëª…": snippet.get("channelTitle"),
                "ì—…ë¡œë“œì¼": published_at,
                "ì¡°íšŒìˆ˜": parse_int(stats.get("viewCount")),
                "ì¢‹ì•„ìš”": parse_int(stats.get("likeCount")),
                "ëŒ“ê¸€ìˆ˜": parse_int(stats.get("commentCount")),
                "ì˜ìƒê¸¸ì´(ë¶„)": round(duration_minutes, 1),
                "ì¸ë„¤ì¼": snippet.get("thumbnails", {})
                .get("high", {})
                .get("url"),
                "ì˜ìƒ ë§í¬": f"https://www.youtube.com/watch?v={item.get('id')}",
            }
        )

    df = pd.DataFrame(rows)
    if not df.empty and df["ì—…ë¡œë“œì¼"].notnull().any():
        df = df.sort_values("ì¡°íšŒìˆ˜", ascending=False)
    return df


@st.cache_data(show_spinner="ğŸ“º ì±„ë„ì„ ê²€ìƒ‰í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
def search_channels(keyword: str, max_results: int = 5):
    youtube = get_youtube_client()

    try:
        search_response = youtube.search().list(
            part="snippet",
            q=keyword,
            type="channel",
            maxResults=max_results,
        ).execute()
    except HttpError as e:
        st.error(f"ìœ íŠœë¸Œ API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return pd.DataFrame()

    channel_items = search_response.get("items", [])
    channel_ids = [item["id"]["channelId"] for item in channel_items]

    if not channel_ids:
        return pd.DataFrame()

    channels_response = youtube.channels().list(
        part="snippet,statistics",
        id=",".join(channel_ids),
    ).execute()

    rows = []
    for item in channels_response.get("items", []):
        snippet = item.get("snippet", {})
        stats = item.get("statistics", {})

        rows.append(
            {
                "channel_id": item.get("id"),
                "ì±„ë„ëª…": snippet.get("title"),
                "ì„¤ëª…": snippet.get("description"),
                "ì¸ë„¤ì¼": snippet.get("thumbnails", {})
                .get("high", {})
                .get("url"),
                "êµ¬ë…ììˆ˜": parse_int(stats.get("subscriberCount")),
                "ì´ì¡°íšŒìˆ˜": parse_int(stats.get("viewCount")),
                "ì˜ìƒìˆ˜": parse_int(stats.get("videoCount")),
                "ì±„ë„ ë§í¬": f"https://www.youtube.com/channel/{item.get('id')}",
            }
        )

    df = pd.DataFrame(rows)
    df = df.sort_values("ì´ì¡°íšŒìˆ˜", ascending=False)
    return df


@st.cache_data(show_spinner="ğŸ“ˆ ì±„ë„ ì˜ìƒ íŒ¨í„´ì„ ë¶„ì„í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
def fetch_channel_videos(channel_id: str, max_results: int = 50):
    """
    íŠ¹ì • ì±„ë„ì˜ ìµœê·¼ ì˜ìƒ ëª©ë¡ + í†µê³„ë¥¼ ìˆ˜ì§‘í•˜ì—¬ DataFrameìœ¼ë¡œ ë°˜í™˜
    """
    youtube = get_youtube_client()

    try:
        search_response = youtube.search().list(
            part="snippet",
            channelId=channel_id,
            type="video",
            order="date",
            maxResults=min(max_results, 50),
        ).execute()
    except HttpError as e:
        st.error(f"ì±„ë„ ì˜ìƒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return pd.DataFrame()

    items = search_response.get("items", [])
    video_ids = [item["id"]["videoId"] for item in items]

    if not video_ids:
        return pd.DataFrame()

    videos_response = youtube.videos().list(
        part="snippet,statistics,contentDetails",
        id=",".join(video_ids),
    ).execute()

    rows = []
    for item in videos_response.get("items", []):
        snippet = item.get("snippet", {})
        stats = item.get("statistics", {})
        content = item.get("contentDetails", {})

        published_at_str = snippet.get("publishedAt")
        try:
            published_at = datetime.fromisoformat(
                published_at_str.replace("Z", "+00:00")
            )
        except Exception:
            published_at = None

        duration_minutes = parse_duration_to_minutes(content.get("duration"))

        rows.append(
            {
                "video_id": item.get("id"),
                "ì œëª©": snippet.get("title"),
                "ì—…ë¡œë“œì¼": published_at,
                "ì¡°íšŒìˆ˜": parse_int(stats.get("viewCount")),
                "ì¢‹ì•„ìš”": parse_int(stats.get("likeCount")),
                "ëŒ“ê¸€ìˆ˜": parse_int(stats.get("commentCount")),
                "ì˜ìƒê¸¸ì´(ë¶„)": round(duration_minutes, 1),
                "ì˜ìƒ ë§í¬": f"https://www.youtube.com/watch?v={item.get('id')}",
            }
        )

    df = pd.DataFrame(rows)
    if df.empty:
        return df

    # ì‹œê°„/ìš”ì¼ íŒŒìƒ ì»¬ëŸ¼
    df["ì—…ë¡œë“œì¼ì‹œ"] = df["ì—…ë¡œë“œì¼"]
    df["ì—…ë¡œë“œ_ìš”ì¼"] = df["ì—…ë¡œë“œì¼ì‹œ"].dt.day_name(locale="ko_KR")
    df["ì—…ë¡œë“œ_ì‹œê°"] = df["ì—…ë¡œë“œì¼ì‹œ"].dt.hour
    return df


# -----------------------------
# í…ìŠ¤íŠ¸ ê¸°ë°˜ í‚¤ì›Œë“œ/SEO ë¶„ì„
# -----------------------------
KOREAN_STOPWORDS = {
    "ì˜ìƒ",
    "ì¡°íšŒìˆ˜",
    "êµ¬ë…",
    "ì±„ë„",
    "ë¸Œì´ë¡œê·¸",
    "ì¼ìƒ",
    "ì‹œí‚¤ê¸°",
    "í•˜ê¸°",
    "í•˜ëŠ”",
    "ê¹Œì§€",
    "ê·¸ë¦¬ê³ ",
    "ê·¼ë°",
    "ì˜¤ëŠ˜",
    "ì´ë²ˆ",
    "ì •ë§",
    "ì§„ì§œ",
    "ì™„ì „",
}


def extract_keywords_from_titles(titles, top_n=15):
    tokens = []
    for t in titles:
        # í•œê¸€/ì˜ë¬¸/ìˆ«ìë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ ì œê±°
        cleaned = re.sub(r"[^0-9A-Za-zê°€-í£\s]", " ", t)
        words = cleaned.split()
        for w in words:
            w = w.strip()
            if len(w) <= 1:
                continue
            if w in KOREAN_STOPWORDS:
                continue
            tokens.append(w)

    counter = Counter(tokens)
    return counter.most_common(top_n)


def suggest_title_templates(best_keywords, base="í‚¤ì›Œë“œ"):
    # ì•„ì£¼ ê°„ë‹¨í•œ í…œí”Œë¦¿ ëª‡ ê°œ
    templates = [
        f"{base}ë§Œ ì•Œë©´ ì¡°íšŒìˆ˜ í„°ì§‘ë‹ˆë‹¤ | {{í‚¤ì›Œë“œ}}",
        f"ì´ˆë³´ë„ ë”°ë¼í•˜ëŠ” {{í‚¤ì›Œë“œ}} ì™„ì „ ì •ë¦¬",
        f"ëª°ëë‹¤ë©´ ì†í•´ì˜€ë˜ {{í‚¤ì›Œë“œ}} ê¿€íŒ 7ê°€ì§€",
        f"êµ¬ë…ìë“¤ì´ ì¢‹ì•„í•˜ëŠ” {{í‚¤ì›Œë“œ}} ì½˜í…ì¸  ë¹„ë°€",
    ]

    # ê°€ì¥ ê°•í•œ í‚¤ì›Œë“œë“¤ë¡œ ì¹˜í™˜ ì˜ˆì‹œ ìƒì„±
    suggestions = []
    for kw in best_keywords[:3]:
        for tpl in templates:
            suggestions.append(tpl.replace("{{í‚¤ì›Œë“œ}}", kw))
    return suggestions


# -----------------------------
# ì‚¬ì´ë“œë°” ì…ë ¥ ì˜ì—­
# -----------------------------
with st.sidebar:
    st.header("ğŸ”§ ë¶„ì„ ì˜µì…˜")

    keyword = st.text_input(
        "ê²€ìƒ‰ í‚¤ì›Œë“œ ì…ë ¥ (ì˜ˆ: ì‹œë‹ˆì–´ ì‡¼í•‘, ê±´ê°•, ìš”ë¦¬)",
        value="ì‹œë‹ˆì–´ ë“œë¼ë§ˆ",
    )

    max_video_results = st.slider(
        "ì˜ìƒ ê²€ìƒ‰ ê°œìˆ˜",
        min_value=5,
        max_value=30,
        value=15,
        step=5,
    )

    st.markdown("---")
    st.markdown("**ì±„ë„ ë¶„ì„ ì˜µì…˜**")
    max_channel_video_results = st.slider(
        "ì±„ë„ íŒ¨í„´ ë¶„ì„ ì‹œ ê°€ì ¸ì˜¬ ìµœê·¼ ì˜ìƒ ìˆ˜",
        min_value=10,
        max_value=50,
        value=30,
        step=10,
    )

# -----------------------------
# ë©”ì¸ íƒ­ êµ¬ì„±
# -----------------------------
tab_videos, tab_channels, tab_patterns, tab_seo = st.tabs(
    ["ğŸ¬ í‚¤ì›Œë“œ ì˜ìƒ ë¶„ì„", "ğŸ“º ì±„ë„ ê²€ìƒ‰Â·ë¹„êµ", "ğŸ“ˆ ì±„ë„ ì˜ìƒ íŒ¨í„´ ë¶„ì„", "ğŸ§  SEOÂ·í‚¤ì›Œë“œ ì¶”ì²œ"]
)

# --------------------------------------------------
# ğŸ¬ 1) í‚¤ì›Œë“œ ì˜ìƒ ë¶„ì„ íƒ­
# --------------------------------------------------
with tab_videos:
    st.subheader("ğŸ¬ í‚¤ì›Œë“œ ê¸°ë°˜ ì¸ê¸° ì˜ìƒ ë¶„ì„")

    if keyword:
        df_videos = search_videos(keyword, max_results=max_video_results)

        if df_videos.empty:
            st.warning("í•´ë‹¹ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰ëœ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            c1, c2 = st.columns([2, 1])
            with c1:
                st.markdown("**ê²€ìƒ‰ ê²°ê³¼ ì˜ìƒ ë¦¬ìŠ¤íŠ¸**")
                st.dataframe(
                    df_videos[
                        [
                            "ì œëª©",
                            "ì±„ë„ëª…",
                            "ì¡°íšŒìˆ˜",
                            "ì¢‹ì•„ìš”",
                            "ëŒ“ê¸€ìˆ˜",
                            "ì˜ìƒê¸¸ì´(ë¶„)",
                            "ì—…ë¡œë“œì¼",
                            "ì˜ìƒ ë§í¬",
                        ]
                    ],
                    use_container_width=True,
                    hide_index=True,
                )

            with c2:
                st.markdown("**ìš”ì•½ í†µê³„**")
                st.metric(
                    "ì´ ì¡°íšŒìˆ˜",
                    f"{df_videos['ì¡°íšŒìˆ˜'].sum():,}",
                )
                st.metric(
                    "í‰ê·  ì¡°íšŒìˆ˜",
                    f"{df_videos['ì¡°íšŒìˆ˜'].mean():,.0f}",
                )
                st.metric(
                    "í‰ê·  ì˜ìƒ ê¸¸ì´(ë¶„)",
                    f"{df_videos['ì˜ìƒê¸¸ì´(ë¶„)'].mean():.1f}",
                )

            st.markdown("### ğŸ” ì¡°íšŒìˆ˜ ìƒìœ„ 5ê°œ ì˜ìƒ")
            st.dataframe(
                df_videos.sort_values("ì¡°íšŒìˆ˜", ascending=False)
                .head(5)[["ì œëª©", "ì±„ë„ëª…", "ì¡°íšŒìˆ˜", "ì¢‹ì•„ìš”", "ì˜ìƒê¸¸ì´(ë¶„)", "ì˜ìƒ ë§í¬"]],
                use_container_width=True,
                hide_index=True,
            )

    else:
        st.info("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ **ê²€ìƒ‰ í‚¤ì›Œë“œ**ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")

# --------------------------------------------------
# ğŸ“º 2) ì±„ë„ ê²€ìƒ‰Â·ë¹„êµ íƒ­
# --------------------------------------------------
with tab_channels:
    st.subheader("ğŸ“º ì±„ë„ ê²€ìƒ‰ ë° ê¸°ë³¸ ì§€í‘œ ë¹„êµ")

    if keyword:
        df_channels = search_channels(keyword, max_results=5)
        if df_channels.empty:
            st.warning("í•´ë‹¹ í‚¤ì›Œë“œì™€ ì—°ê´€ëœ ì±„ë„ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.dataframe(
                df_channels[
                    [
                        "ì±„ë„ëª…",
                        "êµ¬ë…ììˆ˜",
                        "ì´ì¡°íšŒìˆ˜",
                        "ì˜ìƒìˆ˜",
                        "ì±„ë„ ë§í¬",
                    ]
                ],
                use_container_width=True,
                hide_index=True,
            )

            st.markdown("#### ğŸ” ë¶„ì„í•  ì±„ë„ ì„ íƒ")
            channel_options = {
                f"{row['ì±„ë„ëª…']} (êµ¬ë…ì {row['êµ¬ë…ììˆ˜']:,})": row["channel_id"]
                for _, row in df_channels.iterrows()
            }
            selected_label = st.selectbox(
                "ì±„ë„ ì„ íƒ",
                options=list(channel_options.keys()),
            )
            selected_channel_id = channel_options[selected_label]

            st.session_state["selected_channel_for_pattern"] = (
                selected_channel_id,
                selected_label,
            )
            st.success("ì´ ì±„ë„ì´ **íŒ¨í„´ ë¶„ì„ íƒ­**ì—ì„œ ê¸°ë³¸ ì„ íƒìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.")

    else:
        st.info("ì™¼ìª½ì—ì„œ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ë©´ ê´€ë ¨ ì±„ë„ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.")

# --------------------------------------------------
# ğŸ“ˆ 3) ì±„ë„ ì˜ìƒ íŒ¨í„´ ë¶„ì„ íƒ­
# --------------------------------------------------
with tab_patterns:
    st.subheader("ğŸ“ˆ ì±„ë„ ì˜ìƒ íŒ¨í„´ ë¶„ì„")

    default_label = None
    default_channel_id = None
    if "selected_channel_for_pattern" in st.session_state:
        default_channel_id, default_label = st.session_state[
            "selected_channel_for_pattern"
        ]

    st.markdown("**ë¶„ì„í•  ì±„ë„ ID ë˜ëŠ” URLì„ ì§ì ‘ ë„£ì–´ë„ ë©ë‹ˆë‹¤.**")
    input_channel_id = st.text_input(
        "ì±„ë„ ID ë˜ëŠ” ì±„ë„ URL",
        value=default_channel_id or "",
        placeholder="ì˜ˆ) UCxxxxxxxx ë˜ëŠ” https://www.youtube.com/channel/UCxxxx",
    )

    if input_channel_id:
        # URL í˜•íƒœë©´ IDë§Œ ì¶”ì¶œ ì‹œë„
        if "http" in input_channel_id:
            m = re.search(r"/channel/([A-Za-z0-9_-]+)", input_channel_id)
            if m:
                channel_id = m.group(1)
            else:
                st.error("ì±„ë„ URL í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. /channel/ ë’¤ì˜ IDë¥¼ ì‚¬ìš©í•´ ì£¼ì„¸ìš”.")
                st.stop()
        else:
            channel_id = input_channel_id.strip()

        df_channel_videos = fetch_channel_videos(
            channel_id, max_results=max_channel_video_results
        )

        if df_channel_videos.empty:
            st.warning("ì±„ë„ì—ì„œ ë¶„ì„í•  ìˆ˜ ìˆëŠ” ì˜ìƒ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            st.markdown(
                f"ìµœê·¼ {len(df_channel_videos)}ê°œ ì˜ìƒ ê¸°ì¤€ìœ¼ë¡œ íŒ¨í„´ì„ ë¶„ì„í•©ë‹ˆë‹¤."
            )

            # ìƒìœ„ ì˜ìƒ í…Œì´ë¸”
            st.markdown("### ğŸ” ì¡°íšŒìˆ˜ ìƒìœ„ 10ê°œ ì˜ìƒ")
            st.dataframe(
                df_channel_videos.sort_values("ì¡°íšŒìˆ˜", ascending=False)
                .head(10)[
                    [
                        "ì œëª©",
                        "ì¡°íšŒìˆ˜",
                        "ì¢‹ì•„ìš”",
                        "ëŒ“ê¸€ìˆ˜",
                        "ì˜ìƒê¸¸ì´(ë¶„)",
                        "ì—…ë¡œë“œì¼",
                        "ì˜ìƒ ë§í¬",
                    ]
                ],
                use_container_width=True,
                hide_index=True,
            )

            # ì—…ë¡œë“œ ìš”ì¼/ì‹œê°„ íŒ¨í„´
            st.markdown("### ğŸ•’ ì—…ë¡œë“œ ìš”ì¼Â·ì‹œê°„ íŒ¨í„´")

            c1, c2 = st.columns(2)
            with c1:
                pivot_day = (
                    df_channel_videos.groupby("ì—…ë¡œë“œ_ìš”ì¼")["ì¡°íšŒìˆ˜"]
                    .mean()
                    .sort_values(ascending=False)
                )
                st.bar_chart(pivot_day, use_container_width=True)
                st.caption("ìš”ì¼ë³„ í‰ê·  ì¡°íšŒìˆ˜")

            with c2:
                pivot_hour = (
                    df_channel_videos.groupby("ì—…ë¡œë“œ_ì‹œê°")["ì¡°íšŒìˆ˜"]
                    .mean()
                    .sort_index()
                )
                st.line_chart(pivot_hour, use_container_width=True)
                st.caption("ì‹œê°„ëŒ€ë³„ í‰ê·  ì¡°íšŒìˆ˜")

            # ê¸¸ì´ vs ì¡°íšŒìˆ˜
            st.markdown("### â± ì˜ìƒ ê¸¸ì´ vs ì¡°íšŒìˆ˜")
            scatter_df = df_channel_videos[
                ["ì˜ìƒê¸¸ì´(ë¶„)", "ì¡°íšŒìˆ˜"]
            ].dropna()
            if len(scatter_df) >= 2:
                st.scatter_chart(
                    scatter_df,
                    x="ì˜ìƒê¸¸ì´(ë¶„)",
                    y="ì¡°íšŒìˆ˜",
                    use_container_width=True,
                )
            else:
                st.info("ì‚°ì ë„ë¥¼ ê·¸ë¦¬ê¸°ì— ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

            # ìƒìœ„ ì˜ìƒì—ì„œ í‚¤ì›Œë“œ íŒ¨í„´ ì¶”ì¶œ
            st.markdown("### ğŸ§© ìƒìœ„ ì˜ìƒ ì œëª© í‚¤ì›Œë“œ íŒ¨í„´")

            top_titles = (
                df_channel_videos.sort_values("ì¡°íšŒìˆ˜", ascending=False)
                .head(20)["ì œëª©"]
                .tolist()
            )
            kw_counts = extract_keywords_from_titles(top_titles, top_n=15)

            if kw_counts:
                kw_df = pd.DataFrame(
                    kw_counts, columns=["í‚¤ì›Œë“œ", "ë¹ˆë„ìˆ˜"]
                )
                st.dataframe(
                    kw_df,
                    use_container_width=True,
                    hide_index=True,
                )
                best_keywords = [k for k, _ in kw_counts]
                st.success(
                    "ì´ í‚¤ì›Œë“œë“¤ì€ ì´ ì±„ë„ì—ì„œ **ì¡°íšŒìˆ˜ê°€ ì˜ ë‚˜ì˜¨ ì œëª©ì— ìì£¼ ë“±ì¥í•œ ë‹¨ì–´**ë“¤ì…ë‹ˆë‹¤."
                )
            else:
                best_keywords = []
                st.info("í‚¤ì›Œë“œ íŒ¨í„´ì„ ì¶”ì¶œí•  ìˆ˜ ìˆëŠ” ì œëª©ì´ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    else:
        st.info(
            "ë¶„ì„í•  ì±„ë„ ID ë˜ëŠ” URLì„ ì…ë ¥í•˜ê±°ë‚˜, **ì±„ë„ ê²€ìƒ‰ íƒ­ì—ì„œ ì±„ë„ì„ ì„ íƒí•˜ë©´ ìë™ìœ¼ë¡œ ì±„ì›Œì§‘ë‹ˆë‹¤.**"
        )

# --------------------------------------------------
# ğŸ§  4) SEOÂ·í‚¤ì›Œë“œ ì¶”ì²œ íƒ­
# --------------------------------------------------
with tab_seo:
    st.subheader("ğŸ§  SEOÂ·í‚¤ì›Œë“œÂ·ì œëª© ì¶”ì²œ")

    st.markdown(
        "ì´ íƒ­ì€ **í‚¤ì›Œë“œ ë˜ëŠ” ì±„ë„ ìƒìœ„ ì˜ìƒ ì œëª©**ì„ ê¸°ë°˜ìœ¼ë¡œ, "
        "í™œìš©í•˜ê¸° ì¢‹ì€ í‚¤ì›Œë“œì™€ ì œëª© í…œí”Œë¦¿ì„ ì œì•ˆí•©ë‹ˆë‹¤."
    )

    base_text = st.text_area(
        "ë¶„ì„í•  ì œëª© ëª¨ìŒ ë˜ëŠ” í‚¤ì›Œë“œ (ì—¬ëŸ¬ ì¤„ ê°€ëŠ¥)",
        value=keyword or "",
        height=120,
        placeholder="ì˜ˆ) ë‚´ê°€ ì‹¤ì œë¡œ ì¼ë˜ ì˜ìƒ ì œëª©ë“¤, í˜¹ì€ ê´€ì‹¬ í‚¤ì›Œë“œë“¤ì„ ì¤„ë°”ê¿ˆìœ¼ë¡œ ë‚˜ì—´",
    )

    if st.button("ğŸ” í‚¤ì›Œë“œ/ì œëª© ë¶„ì„ ì‹¤í–‰"):
        lines = [l.strip() for l in base_text.split("\n") if l.strip()]
        if not lines:
            st.warning("ë¶„ì„í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        else:
            kw_counts = extract_keywords_from_titles(lines, top_n=20)
            if not kw_counts:
                st.info("ìœ ì˜ë¯¸í•œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë¡œ ì‹œë„í•´ ë³´ì„¸ìš”.")
            else:
                st.markdown("### ğŸ”‘ ì¶”ì²œ í‚¤ì›Œë“œ (ì œëª©ì— ìì£¼ ì“°ì¸ ë‹¨ì–´)")
                kw_df = pd.DataFrame(kw_counts, columns=["í‚¤ì›Œë“œ", "ë¹ˆë„ìˆ˜"])
                st.dataframe(
                    kw_df,
                    use_container_width=True,
                    hide_index=True,
                )

                strong_keywords = [k for k, _ in kw_counts]
                st.markdown("### âœ ì¶”ì²œ ì œëª© í…œí”Œë¦¿ ì˜ˆì‹œ")
                title_suggestions = suggest_title_templates(
                    strong_keywords, base="ì¡°íšŒìˆ˜ ì˜¬ë¦¬ëŠ”"
                )

                for i, t in enumerate(title_suggestions, start=1):
                    st.write(f"{i}. {t}")

                st.caption(
                    "â€» ìœ„ ì œëª©ì€ ê·¸ëŒ€ë¡œ ì¨ë„ ë˜ì§€ë§Œ, ì±„ë„ í†¤ì•¤ë§¤ë„ˆì— ë§ê²Œ ì‚´ì§ë§Œ ìˆ˜ì •í•´ì„œ ì“°ë©´ ë” ìì—°ìŠ¤ëŸ½ìŠµë‹ˆë‹¤."
                )
    else:
        st.info("ë¶„ì„í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•œ ë’¤, **[ğŸ” í‚¤ì›Œë“œ/ì œëª© ë¶„ì„ ì‹¤í–‰]** ë²„íŠ¼ì„ ëˆŒëŸ¬ ì£¼ì„¸ìš”.")
