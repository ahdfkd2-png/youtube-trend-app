import streamlit as st
import re
import os
import json
from collections import Counter
from datetime import datetime, timezone, timedelta
from typing import List, Dict, Tuple

import pandas as pd
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError


# ----------------------------
# ê¸°ë³¸ ì„¤ì •
# ----------------------------

st.set_page_config(
    page_title="YouTube íŠ¸ë Œë“œÂ·ì±„ë„ ë¶„ì„ê¸° (v5.0 - FINAL)",
    page_icon="ğŸ“Š",
    layout="wide",
)

st.markdown(
    """
    <style>
    /* ì „ì²´ í°íŠ¸/ì—¬ë°± ì¡°ê¸ˆ ë‹¤ë“¬ê¸° */
    .main-block {padding-top: 0rem;}
    .block-container {padding-top: 1.5rem;}
    /* ì „ë¬¸ ë¶„ì„ ë„êµ¬ ëŠë‚Œì„ ìœ„í•œ í—¤ë” í°íŠ¸ í¬ê¸° ì¡°ì • */
    h1 {font-size: 2.2rem;} 
    h2 {font-size: 1.7rem;}
    </style>
    """,
    unsafe_allow_html=True,
)


# ----------------------------
# ìœ í‹¸ í•¨ìˆ˜ (UTILITIES)
# ----------------------------

def get_api_key() -> str:
    """Streamlit Secrets ì—ì„œ API KEY ê°€ì ¸ì˜¤ê¸°"""
    key = st.secrets.get("YOUTUBE_API_KEY", "")
    if not key:
        st.error("âŒ YOUTUBE_API_KEY ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit â†’ App Settings â†’ Secrets ì—ì„œ ì„¤ì •í•´ ì£¼ì„¸ìš”.")
    return key


def build_youtube(api_key: str):
    """YouTube í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    return build("youtube", "v3", developerKey=api_key)


def parse_iso_duration(duration: str) -> int:
    """ISO8601 duration(ì˜ˆ: 'PT15M33S') â†’ ì´ˆ ë‹¨ìœ„ ì •ìˆ˜ë¡œ ë³€í™˜"""
    if not duration:
        return 0
    pattern = re.compile(r"PT(?:(\d+)H)?(?:(\d+)M)?(?:(\d+)S)?")
    match = pattern.match(duration)
    if not match:
        return 0
    hours, mins, secs = match.groups()
    hours = int(hours) if hours else 0
    mins = int(mins) if mins else 0
    secs = int(secs) if secs else 0
    return hours * 3600 + mins * 60 + secs


def weekday_kr_from_ts(ts: pd.Timestamp) -> str:
    """ìš”ì¼ì„ í•œêµ­ì–´ í•œ ê¸€ìë¡œ ë°˜í™˜"""
    mapping = {0: "ì›”", 1: "í™”", 2: "ìˆ˜", 3: "ëª©", 4: "ê¸ˆ", 5: "í† ", 6: "ì¼"}
    return mapping.get(ts.weekday(), "")


def extract_channel_id(raw: str) -> str:
    """ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê°’ì—ì„œ channelId ì¶”ì¶œ"""
    raw = raw.strip()
    if "youtube.com/channel/" in raw:
        return raw.split("youtube.com/channel/")[-1].split("/")[0].split("?")[0]
    if "youtube.com/" in raw:
        path = raw.split("youtube.com/")[-1]
        return path.split("/")[-1].split("?")[0]
    return raw


def safe_int(x):
    try:
        return int(x)
    except Exception:
        return 0


def format_korean_unit(number):
    """ìˆ«ìë¥¼ í•œêµ­ì–´ ë‹¨ìœ„(ë§Œ, ì–µ)ë¡œ í¬ë§·íŒ…"""
    if number >= 100000000:
        return f"{number / 100000000:.1f}ì–µ"
    elif number >= 10000:
        return f"{number / 10000:.1f}ë§Œ"
    else:
        return f"{number:,}"

# --- UPGRADE: 4ë‹¨ê³„ - ì„±ê³¼ ê°€ì¤‘ì¹˜ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜ ---

def extract_keywords_with_weight(df: pd.DataFrame, top_n: int = 30) -> pd.DataFrame:
    """
    UPGRADE: ì¡°íšŒìˆ˜(views)ë¥¼ ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš©í•˜ì—¬ í‚¤ì›Œë“œ ì ìˆ˜ë¥¼ ë§¤ê¸°ê³  ì¶”ì¶œ
    """
    if df.empty:
        return pd.DataFrame(columns=["keyword", "score"])

    # 1. ë¶ˆìš©ì–´(Stopwords) í™•ì¥ ë° ì •ì˜
    stopwords = {
        "ì˜ìƒ", "official", "video", "the", "and", "for", "with", "full", "ver",
        "episode", "ep", "live", "tv", "show", "channel", "shorts", "ê³µì‹", 
        "í•˜ì´ë¼ì´íŠ¸", "í´ë¦½", "ë¬´ëŒ€", "ìµœì‹ ", "today", "day", "in", "of", "a", 
        "ì´ë²ˆì£¼", "ë‹¤ì‹œë³´ê¸°", "ëª¨ìŒ", "ì´ì •ë¦¬", "ìµœê³ ", "ì˜¤ëŠ˜", "ì§€ê¸ˆ", "ë°”ë¡œ",
        "story", "log", "vlog", "asmr", "asmr", "tip", "ê¿€íŒ", "ë°©ë²•", "í•˜ëŠ”ë²•",
        "ì €ì¥", "êµ¬ë…", "ì¢‹ì•„ìš”", "ëŒ“ê¸€", "ì•Œë¦¼", "ì„¤ì •", "í•˜ë‚˜", "ë‘ê°œ"
    }

    keyword_scores = Counter()

    for _, row in df.iterrows():
        title = row["title"].lower()
        views = row["views"]
        
        # ì¡°íšŒìˆ˜ì˜ ì œê³±ê·¼ì„ ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš©
        weight = views ** 0.5 
        
        # ì •ê·œì‹ì„ ì‚¬ìš©í•˜ì—¬ í•œê¸€, ì˜ì–´, ìˆ«ìë§Œ ì¶”ì¶œ
        tokens = re.findall(r"[ê°€-í£a-zA-Z0-9]+", title)
        
        # í•„í„°ë§ ë° ì ìˆ˜ í•©ì‚°
        for t in tokens:
            if len(t) >= 2 and t not in stopwords:
                keyword_scores[t] += weight
    
    if not keyword_scores:
        return pd.DataFrame(columns=["keyword", "score"])
        
    data = pd.DataFrame(
        [{"keyword": k, "score": v} for k, v in keyword_scores.most_common(top_n)]
    )
    data["score"] = data["score"].round(0).astype(int)
    
    return data


# --- UPGRADE: 3ë‹¨ê³„ - íˆìŠ¤í† ë¦¬ ì €ì¥/ë¡œë“œ ë° ë“±ê¸‰ ë¶€ì—¬ í•¨ìˆ˜ ---

HISTORY_FILE = "channel_history.json"


def save_channel_history(history_data: Dict):
    """ì±„ë„ íˆìŠ¤í† ë¦¬ ë°ì´í„°ë¥¼ JSON íŒŒì¼ì— ì €ì¥"""
    try:
        with open(HISTORY_FILE, "w", encoding="utf-8") as f:
            json.dump(history_data, f, ensure_ascii=False, indent=4)
    except Exception as e:
        st.error(f"âŒ íˆìŠ¤í† ë¦¬ ì €ì¥ ì‹¤íŒ¨: {e}")


def load_channel_history() -> Dict:
    """JSON íŒŒì¼ì—ì„œ ì±„ë„ íˆìŠ¤í† ë¦¬ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°"""
    if not os.path.exists(HISTORY_FILE):
        return {}
    try:
        with open(HISTORY_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return {}


def assign_channel_grade(info: Dict, recent_df: pd.DataFrame) -> str:
    """ì±„ë„ ë“±ê¸‰ (A1~C3)ì„ ë¶€ì—¬í•˜ëŠ” ê°„ë‹¨í•œ ë¡œì§"""
    if recent_df.empty or info['subscriber_count'] == 0:
        return "ë“±ê¸‰ ì™¸"

    # 1. ê·œëª¨ ì ìˆ˜ (êµ¬ë…ì ìˆ˜) - 40%
    sub_count = info['subscriber_count']
    if sub_count >= 100000: rank_sub = 3
    elif sub_count >= 10000: rank_sub = 2
    else: rank_sub = 1
    
    # 2. í™œë™ ì ìˆ˜ (ì¼ í‰ê·  ì¡°íšŒìˆ˜) - 60%
    avg_daily_views = recent_df['views_per_day'].mean()
    if sub_count > 0:
        daily_ratio = avg_daily_views / sub_count * 1000
    else:
        daily_ratio = 0
        
    if daily_ratio >= 10: rank_activity = 3
    elif daily_ratio >= 3: rank_activity = 2
    else: rank_activity = 1
    
    final_score = (rank_sub * 0.4 + rank_activity * 0.6)
    
    if final_score >= 2.6: grade_char = 'A'
    elif final_score >= 1.8: grade_char = 'B'
    else: grade_char = 'C'
        
    grade_num = 1
    if sub_count < 10000: grade_num = 3
    elif sub_count < 50000 and daily_ratio < 5: grade_num = 2 
    elif sub_count >= 100000 and daily_ratio >= 10: grade_num = 1
        
    return f"{grade_char}{grade_num}"


def get_channel_summary_row(info: Dict, df: pd.DataFrame) -> Dict:
    """ì±„ë„ íˆìŠ¤í† ë¦¬ì— ì €ì¥í•  í•µì‹¬ ë°ì´í„° ìš”ì•½"""
    if df.empty:
        return {}
        
    now = datetime.now(timezone.utc)
    recent_30d = df[df["published_at"] > (now - timedelta(days=30))]

    row = {
        "channel_id": info["channel_id"],
        "title": info["title"],
        "subscriber_count": info["subscriber_count"],
        "total_views": info["view_count"],
        "video_count": info["video_count"],
        "analysis_date": now.strftime('%Y-%m-%d %H:%M'),
        "recent_video_count": len(df),
        "recent_avg_views": int(df["views"].mean()),
        "recent_avg_daily_views": int(df["views_per_day"].mean()),
        "videos_last_30d": len(recent_30d),
        "grade": assign_channel_grade(info, df)
    }
    return row

# ----------------------------
# ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ìºì‹œ ì ìš©)
# ----------------------------

@st.cache_data(ttl=3600, show_spinner=False)
def fetch_videos_by_keyword(api_key: str, keyword: str, max_results: int) -> pd.DataFrame:
    # (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼í•˜ê²Œ ìœ ì§€)
    youtube = build_youtube(api_key)
    max_results = max(1, min(max_results, 50))
    search_resp = youtube.search().list(
        part="snippet", q=keyword, type="video", order="relevance", maxResults=max_results,
    ).execute()

    video_ids = [item["id"]["videoId"] for item in search_resp.get("items", [])]
    if not video_ids: return pd.DataFrame()

    videos_resp = youtube.videos().list(
        part="snippet,contentDetails,statistics", id=",".join(video_ids), maxResults=len(video_ids),
    ).execute()

    rows = []
    for item in videos_resp.get("items", []):
        snippet = item.get("snippet", {}); stats = item.get("statistics", {}); content = item.get("contentDetails", {})
        published_at = snippet.get("publishedAt")
        try: ts = pd.to_datetime(published_at).replace(tzinfo=timezone.utc)
        except Exception: ts = pd.NaT
        duration_sec = parse_iso_duration(content.get("duration", ""))

        rows.append(
            {
                "video_id": item.get("id"), "title": snippet.get("title"), "description": snippet.get("description", ""),
                "channel_title": snippet.get("channelTitle"), "channel_id": snippet.get("channelId"), "published_at": ts,
                "views": safe_int(stats.get("viewCount")), "likes": safe_int(stats.get("likeCount")), "comments": safe_int(stats.get("commentCount")),
                "duration_sec": duration_sec, "thumbnail_url": snippet.get("thumbnails", {}).get("medium", {}).get("url", ""),
            }
        )

    df = pd.DataFrame(rows)
    if df.empty: return df
    now = datetime.now(timezone.utc)
    df["days_since_publish"] = (now - df["published_at"]).dt.total_seconds() / (3600 * 24)
    df["days_since_publish"] = df["days_since_publish"].replace(0, 0.1)
    df["views_per_day"] = df["views"] / df["days_since_publish"]
    df["duration_min"] = df["duration_sec"] / 60
    df["weekday"] = df["published_at"].apply(weekday_kr_from_ts)
    df["publish_hour"] = df["published_at"].dt.hour
    df["max_watch_time_min"] = df["duration_min"] * df["views"]
    return df.sort_values("views", ascending=False).reset_index(drop=True)


@st.cache_data(ttl=3600, show_spinner=False)
def fetch_channel_basic(api_key: str, channel_id: str) -> Dict:
    # (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼í•˜ê²Œ ìœ ì§€)
    youtube = build_youtube(api_key)
    resp = youtube.channels().list(
        part="snippet,statistics,contentDetails", id=channel_id, maxResults=1,
    ).execute()

    items = resp.get("items", [])
    if not items: return {}

    item = items[0]
    stats = item.get("statistics", {}); snippet = item.get("snippet", {})

    return {
        "channel_id": item.get("id"), "title": snippet.get("title"), "description": snippet.get("description", ""),
        "published_at": pd.to_datetime(snippet.get("publishedAt")).replace(tzinfo=timezone.utc),
        "subscriber_count": safe_int(stats.get("subscriberCount")), "video_count": safe_int(stats.get("videoCount")),
        "view_count": safe_int(stats.get("viewCount")), "thumbnail_url": snippet.get("thumbnails", {}).get("medium", {}).get("url", ""),
    }


@st.cache_data(ttl=3600, show_spinner=False)
def fetch_channel_recent_videos(
    api_key: str, channel_id: str, max_results: int
) -> pd.DataFrame:
    # (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼í•˜ê²Œ ìœ ì§€)
    youtube = build_youtube(api_key)
    max_results = max(1, min(max_results, 50))
    search_resp = youtube.search().list(
        part="snippet", channelId=channel_id, type="video", order="date", maxResults=max_results,
    ).execute()

    video_ids = [item["id"]["videoId"] for item in search_resp.get("items", [])]
    if not video_ids: return pd.DataFrame()

    videos_resp = youtube.videos().list(
        part="snippet,contentDetails,statistics", id=",".join(video_ids), maxResults=len(video_ids),
    ).execute()

    rows = []
    for item in videos_resp.get("items", []):
        snippet = item.get("snippet", {}); stats = item.get("statistics", {}); content = item.get("contentDetails", {})
        published_at = snippet.get("publishedAt")
        try: ts = pd.to_datetime(published_at).replace(tzinfo=timezone.utc)
        except Exception: ts = pd.NaT
        duration_sec = parse_iso_duration(content.get("duration", ""))

        rows.append(
            {
                "video_id": item.get("id"), "title": snippet.get("title"), "description": snippet.get("description", ""),
                "published_at": ts, "views": safe_int(stats.get("viewCount")), "likes": safe_int(stats.get("likeCount")),
                "comments": safe_int(stats.get("commentCount")), "duration_sec": duration_sec,
                "thumbnail_url": snippet.get("thumbnails", {}).get("medium", {}).get("url", ""),
            }
        )

    df = pd.DataFrame(rows)
    if df.empty: return df
    now = datetime.now(timezone.utc)
    df["days_since_publish"] = (now - df["published_at"]).dt.total_seconds() / (3600 * 24)
    df["days_since_publish"] = df["days_since_publish"].replace(0, 0.1)
    df["views_per_day"] = df["views"] / df["days_since_publish"]
    df["duration_min"] = df["duration_sec"] / 60
    df["weekday"] = df["published_at"].apply(weekday_kr_from_ts)
    df["publish_hour"] = df["published_at"].dt.hour
    df["max_watch_time_min"] = df["duration_min"] * df["views"]
    return df.sort_values("published_at", ascending=False).reset_index(drop=True)


# ----------------------------
# SEO / í‚¤ì›Œë“œ ë¶„ì„
# ----------------------------
def render_keyword_suggestions(df: pd.DataFrame):
    """
    UPGRADE: ê°€ì¤‘ì¹˜ ê¸°ë°˜ìœ¼ë¡œ í‚¤ì›Œë“œ ì¶”ì²œì„ ë Œë”ë§
    """
    st.subheader("ğŸ” SEO í‚¤ì›Œë“œ/íƒœê·¸ ì•„ì´ë””ì–´")
    if df.empty:
        st.info("ë¶„ì„í•  ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.");
        return
        
    kw_df = extract_keywords_with_weight(df, top_n=30)
    
    if kw_df.empty:
        st.info("ì¶”ì¶œëœ í‚¤ì›Œë“œê°€ ê±°ì˜ ì—†ìŠµë‹ˆë‹¤. ì œëª© íŒ¨í„´ì´ ë„ˆë¬´ ë‹¨ìˆœí•˜ê±°ë‚˜ ë¶ˆìš©ì–´ë§Œ í¬í•¨í•˜ê³  ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.");
        return

    col1, col2 = st.columns([2, 1])
    with col1:
        st.markdown("**ì„±ê³¼ ê°€ì¤‘ì¹˜ ê¸°ë°˜ TOP 30 í‚¤ì›Œë“œ**")
        st.dataframe(
            kw_df.rename(columns={"score": "ì„±ê³¼ ì ìˆ˜"}), 
            use_container_width=True, 
            hide_index=True
        )
        st.caption("â€» 'ì„±ê³¼ ì ìˆ˜'ëŠ” ì¡°íšŒìˆ˜ê°€ ë†’ì€ ì˜ìƒì˜ ì œëª©ì— ë“±ì¥í• ìˆ˜ë¡ ë†’ì•„ì§‘ë‹ˆë‹¤.")

    with col2:
        st.markdown("**íƒœê·¸ë¡œ ì¨ë³¼ ë§Œí•œ í›„ë³´**")
        tag_candidates = kw_df["keyword"].tolist()[:15]
        st.code(", ".join(tag_candidates), language="text")
        st.caption("â€» ì´ í‚¤ì›Œë“œë¥¼ ì œëª©, ì„¤ëª…, íƒœê·¸ì— í™œìš©í•´ ë³´ì„¸ìš”.")

# ----------------------------
# ìš”ì•½ ë©”ì‹œì§€ ìƒì„± (ë£° ê¸°ë°˜)
# ----------------------------

def make_simple_summary_for_channel(df: pd.DataFrame) -> str:
    # (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼í•˜ê²Œ ìœ ì§€)
    if df.empty: return "ìµœê·¼ ì˜ìƒ ë°ì´í„°ê°€ ì—†ì–´ íŒ¨í„´ì„ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    n = len(df); avg_views = int(df["views"].mean()); median_views = int(df["views"].median())
    max_views = int(df["views"].max()); short = df[df["duration_min"] <= 8]; long = df[df["duration_min"] >= 20]
    parts = []
    parts.append(f"ìµœê·¼ {n}ê°œ ì˜ìƒ ê¸°ì¤€ìœ¼ë¡œ í‰ê·  ì¡°íšŒìˆ˜ëŠ” ì•½ {avg_views:,}íšŒ, ì¤‘ì•™ê°’ì€ {median_views:,}íšŒì…ë‹ˆë‹¤.")
    parts.append(f"ê°€ì¥ ë§ì´ ë³¸ ì˜ìƒì€ ì•½ {max_views:,}íšŒê¹Œì§€ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.")
    if not short.empty and not long.empty:
        short_avg = int(short["views"].mean()); long_avg = int(long["views"].mean())
        if short_avg > long_avg * 1.3:
            parts.append(f"8ë¶„ ì´í•˜ ì§§ì€ ì˜ìƒì˜ í‰ê·  ì¡°íšŒìˆ˜ê°€ {short_avg:,}íšŒë¡œ, 20ë¶„ ì´ìƒ ê¸´ ì˜ìƒ({long_avg:,}íšŒ)ë³´ë‹¤ ê½¤ ì˜ ë‚˜ì˜¤ëŠ” í¸ì…ë‹ˆë‹¤. " "ì§§ì€ ê¸¸ì´ì˜ ì½˜í…ì¸  ë¹„ì¤‘ì„ ì¡°ê¸ˆ ë” ëŠ˜ë ¤ë³´ëŠ” ê²ƒë„ ì¢‹ê² ìŠµë‹ˆë‹¤.")
        elif long_avg > short_avg * 1.3:
            parts.append(f"20ë¶„ ì´ìƒ ê¸´ ì˜ìƒì˜ í‰ê·  ì¡°íšŒìˆ˜ê°€ {long_avg:,}íšŒë¡œ, 8ë¶„ ì´í•˜ ì˜ìƒ({short_avg:,}íšŒ)ë³´ë‹¤ ìœ ë¦¬í•©ë‹ˆë‹¤. " "ê¹Šì´ ìˆëŠ” ì¥í¸ ì½˜í…ì¸ ê°€ ì±„ë„ì— ì˜ ë§ëŠ” í¸ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.")
    weekday_mean = df.groupby("weekday")["views"].mean().sort_values(ascending=False)
    if len(weekday_mean) >= 3:
        best_day = weekday_mean.index[0]
        parts.append(f"ìš”ì¼ë³„ í‰ê·  ì¡°íšŒìˆ˜ëŠ” **{best_day}ìš”ì¼ ì—…ë¡œë“œë¶„**ì´ ê°€ì¥ ë†’ê²Œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤. " "í•´ë‹¹ ìš”ì¼ ì „í›„ë¡œ ì¤‘ìš”í•œ ì˜ìƒì„ ë°°ì¹˜í•˜ëŠ” ì „ëµì„ ê³ ë ¤í•´ë³¼ ë§Œí•©ë‹ˆë‹¤.")
    return "\n\n".join(parts)


# ----------------------------
# í™”ë©´ êµ¬ì„± í•¨ìˆ˜ë“¤
# ----------------------------

def render_channel_kpi_cards(info: Dict, df: pd.DataFrame):
    """
    UPGRADE: ì±„ë„ ë¶„ì„ í˜ì´ì§€ ìƒë‹¨ì— êµ¬ë…ì, ì´ ì¡°íšŒìˆ˜, í‰ê·  ì¡°íšŒìˆ˜, ì„±ì¥ë¥ ì„ ë³´ì—¬ì£¼ëŠ” KPI ì¹´ë“œ 4ê°œ ë°°ì¹˜
    """
    st.markdown("### ğŸ† ì±„ë„ í•µì‹¬ ì§€í‘œ (Channel KPIs)")
    
    days_since_start = (datetime.now(timezone.utc) - info["published_at"]).total_seconds() / (3600 * 24)
    channel_avg_views_per_day = info["view_count"] / max(days_since_start, 1)

    recent_avg_views_per_day = df["views_per_day"].mean() if not df.empty else 0
    
    growth_delta = 0.0
    if channel_avg_views_per_day > 0:
        growth_delta = ((recent_avg_views_per_day - channel_avg_views_per_day) / channel_avg_views_per_day) * 100
        
    growth_str = f"{growth_delta:.1f}%"
    
    col1, col2, col3, col4 = st.columns(4)

    col1.metric(
        label="â­ êµ¬ë…ì", 
        value=format_korean_unit(info["subscriber_count"]),
        delta=f"ì´ ì˜ìƒ ìˆ˜: {info['video_count']:,}",
        delta_color="off"
    )
    
    col2.metric(
        label="ğŸŒ ì´ ì¡°íšŒìˆ˜", 
        value=format_korean_unit(info["view_count"]),
        delta=f"ê°œì„¤ì¼: {info['published_at'].strftime('%Y.%m.%d')}",
        delta_color="off"
    )

    col3.metric(
        label=f"ğŸ“Š ìµœê·¼ í‰ê·  ì¡°íšŒìˆ˜ (ì˜ìƒ {len(df)}ê°œ)", 
        value=f"{int(df['views'].mean()):,}" if not df.empty else "N/A",
        delta=f"ì¤‘ì•™ê°’: {int(df['views'].median()):,}" if not df.empty else "",
        delta_color="off"
    )

    col4.metric(
        label="ğŸš€ ì¼ì¼ ì„±ê³¼ ë³€í™”ìœ¨ (ìµœê·¼ ì˜ìƒ)", 
        value=f"{int(recent_avg_views_per_day):,}íšŒ/ì¼",
        delta=growth_str,
        delta_color="inverse" if growth_delta < 0 else "normal"
    )

def render_basic_stats_cards_for_videos(df: pd.DataFrame, title: str):
    """
    UPGRADE: í‚¤ì›Œë“œ ë¶„ì„ í˜ì´ì§€ì˜ ê¸°ë³¸ í†µê³„ ì¹´ë“œë¥¼ ê¹”ë”í•˜ê²Œ ì¬êµ¬ì„±
    """
    st.subheader(title)

    if df.empty: st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); return

    total_views = int(df["views"].sum())
    avg_views = int(df["views"].mean())
    median_views = int(df["views"].median())
    total_max_watch_min = int(df["max_watch_time_min"].sum())
    
    col1, col2, col3 = st.columns(3)
    
    col1.metric("ì˜ìƒ ìˆ˜", f"{len(df):,}")
    col2.metric("ì´ ì¡°íšŒìˆ˜", f"{total_views:,}")
    col3.metric("í‰ê·  ì¡°íšŒìˆ˜", f"{avg_views:,}")
    
    st.caption(f"â€» ë¶„ì„ëœ ì˜ìƒì˜ ì¤‘ì•™ê°’ ì¡°íšŒìˆ˜ëŠ” {median_views:,}íšŒì´ë©°, ì´ë¡ ìƒ ìµœëŒ€ ì‹œì²­ì‹œê°„ì€ {total_max_watch_min:,}ë¶„ì…ë‹ˆë‹¤. ")


def render_video_table(df: pd.DataFrame):
    # (ê¸°ì¡´ ì½”ë“œì—ì„œ ì±„ë„ëª… ì¹¼ëŸ¼ ì¶”ê°€)
    if df.empty: return

    show_cols = [
        "title", "channel_title", "views", "views_per_day",
        "duration_min", "weekday", "publish_hour", "published_at",
    ]
    rename = {
        "title": "ì œëª©", "channel_title": "ì±„ë„ëª…", "views": "ì¡°íšŒìˆ˜",
        "views_per_day": "ì¼ í‰ê·  ì¡°íšŒìˆ˜", "duration_min": "ê¸¸ì´(ë¶„)",
        "weekday": "ìš”ì¼", "publish_hour": "ì—…ë¡œë“œ ì‹œê°„(ì‹œ)", "published_at": "ì—…ë¡œë“œ ì¼ì‹œ",
    }

    st.markdown("#### ğŸ“‹ ìƒì„¸ ì˜ìƒ ë¦¬ìŠ¤íŠ¸")
    st.dataframe(
        df[[c for c in show_cols if c in df.columns]].rename(columns=rename),
        use_container_width=True, hide_index=True,
    )


def render_pattern_charts(df: pd.DataFrame):
    # (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼í•˜ê²Œ ìœ ì§€)
    if df.empty: return
    st.subheader("ğŸ“ˆ íŒ¨í„´ ë¶„ì„")
    c1, c2 = st.columns(2)
    with c1:
        st.markdown("**ìš”ì¼ë³„ í‰ê·  ì¡°íšŒìˆ˜**")
        weekday_order = ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"]
        weekday_mean = (
            df.groupby("weekday")["views"].mean().reindex(weekday_order).dropna().astype(int)
        )
        if not weekday_mean.empty: st.bar_chart(weekday_mean)
    with c2:
        st.markdown("**ì—…ë¡œë“œ ì‹œê°„ëŒ€ë³„ í‰ê·  ì¡°íšŒìˆ˜**")
        hour_mean = df.groupby("publish_hour")["views"].mean().astype(int)
        if not hour_mean.empty: st.bar_chart(hour_mean)
    c3, c4 = st.columns(2)
    with c3:
        st.markdown("**ì˜ìƒ ê¸¸ì´(ë¶„) vs ì¡°íšŒìˆ˜**")
        st.scatter_chart(
            df[["duration_min", "views"]].rename(
                columns={"duration_min": "ê¸¸ì´(ë¶„)", "views": "ì¡°íšŒìˆ˜"}
            )
        )
    with c4:
        st.markdown("**ì—…ë¡œë“œ í›„ ê²½ê³¼ì¼ vs ì¼ í‰ê·  ì¡°íšŒìˆ˜**")
        st.scatter_chart(
            df[["days_since_publish", "views_per_day"]].rename(
                columns={"days_since_publish": "ì—…ë¡œë“œ í›„ ê²½ê³¼ì¼", "views_per_day": "ì¼ í‰ê·  ì¡°íšŒìˆ˜",}
            )
        )


def render_top_thumbnails(df: pd.DataFrame):
    # (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼í•˜ê²Œ ìœ ì§€)
    if df.empty: return
    st.subheader("ğŸ† ìƒìœ„ ì„±ê³¼ ì˜ìƒ ì¸ë„¤ì¼ (TOP 3)")
    top3 = df.sort_values("views", ascending=False).head(3)
    cols = st.columns(3)
    for col, (_, row) in zip(cols, top3.iterrows()):
        with col:
            if row["thumbnail_url"]: st.image(row["thumbnail_url"])
            st.markdown(f"**{row['title']}**")
            st.caption(f"ì¡°íšŒìˆ˜: {row['views']:,}íšŒ")


# ----------------------------
# ê° ë¶„ì„ ëª¨ë“œ ë Œë”ë§
# ----------------------------

def page_keyword_trend(api_key: str, video_limit: int):
    st.title("ğŸ¯ í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¶„ì„")
    st.markdown("##### í˜„ì¬ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ìœ íŠœë¸Œ íŠ¸ë Œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")

    keyword = st.text_input("ë¶„ì„í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì‹œë‹ˆì–´ ì‡¼í•‘, ê±´ê°•, ìš”ë¦¬ ë“±)", key="kw_input")
    st.caption(f"â€» ê°€ì ¸ì˜¬ ì˜ìƒ ìˆ˜: {video_limit}ê°œ. API í• ë‹¹ëŸ‰ ì†Œëª¨ì— ì£¼ì˜í•˜ì„¸ìš”.")

    if not keyword: st.info("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•œ ë’¤ Enter ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”."); return

    try:
        with st.spinner(f"í‚¤ì›Œë“œ '{keyword}' ê´€ë ¨ YouTube ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
            df = fetch_videos_by_keyword(api_key, keyword, video_limit)
    except HttpError as e:
        msg = str(e)
        if "quotaExceeded" in msg: st.error("âŒ YouTube API ì¼ì¼ í• ë‹¹ëŸ‰ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‚´ì¼ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜, ê°€ì ¸ì˜¬ ì˜ìƒ ìˆ˜ë¥¼ ì¤„ì—¬ ì£¼ì„¸ìš”.")
        elif "keyInvalid" in msg: st.error("âŒ YouTube API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í‚¤ë¥¼ ë‹¤ì‹œ í™•ì¸í•´ ì£¼ì„¸ìš”.")
        else: st.error(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {msg}")
        return

    if df.empty: st.warning("ê²€ìƒ‰ëœ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤."); return

    st.markdown("---")
    render_basic_stats_cards_for_videos(df, f"'{keyword}' ê´€ë ¨ ì˜ìƒ ìš”ì•½")
    st.markdown("---")
    render_top_thumbnails(df)
    st.markdown("---")
    
    c_chart, c_seo = st.columns([3, 2])
    with c_chart: render_pattern_charts(df)
    with c_seo: render_keyword_suggestions(df)
        
    st.markdown("---")
    render_video_table(df)


def page_single_channel(api_key: str, video_limit: int):
    st.title("ğŸ¯ íŠ¹ì • ì±„ë„ ì‹¬ì¸µ ë¶„ì„")
    st.markdown("##### ì±„ë„ì˜ ê¸°ë³¸ ì§€í‘œ, ìµœê·¼ ì˜ìƒ íŒ¨í„´, SEO ì „ëµì„ ë¶„ì„í•©ë‹ˆë‹¤.")

    raw_input = st.text_input(
        "ì±„ë„ ID ë˜ëŠ” ì±„ë„ URLì„ ì…ë ¥í•˜ì„¸ìš”", key="ch_input",
        help="UC ë¡œ ì‹œì‘í•˜ëŠ” ID, ë˜ëŠ” https://www.youtube.com/channel/ í˜•íƒœë¥¼ ì…ë ¥í•˜ì„¸ìš”.",
    )

    if not raw_input: st.info("ë¶„ì„í•  ì±„ë„ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”."); return

    channel_id = extract_channel_id(raw_input)

    try:
        with st.spinner("ì±„ë„/ì˜ìƒ ë°ì´í„° ìˆ˜ì§‘ ì¤‘..."):
            info = fetch_channel_basic(api_key, channel_id)
            df = fetch_channel_recent_videos(api_key, channel_id, video_limit)
    except HttpError as e:
        msg = str(e)
        if "quotaExceeded" in msg: st.error("âŒ YouTube API ì¼ì¼ í• ë‹¹ëŸ‰ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‚´ì¼ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜, ê°€ì ¸ì˜¬ ì˜ìƒ ìˆ˜ë¥¼ ì¤„ì—¬ ì£¼ì„¸ìš”.")
        elif "keyInvalid" in msg: st.error("âŒ YouTube API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í‚¤ë¥¼ ë‹¤ì‹œ í™•ì¸í•´ ì£¼ì„¸ìš”.")
        else: st.error(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {msg}")
        return

    if not info: st.error("ì±„ë„ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì±„ë„ ID/URLì„ ë‹¤ì‹œ í™•ì¸í•´ ì£¼ì„¸ìš”."); return
    
    # --- UPGRADE: ì±„ë„ íˆìŠ¤í† ë¦¬ ì €ì¥ ê¸°ëŠ¥ ì¶”ê°€ ë° ë“±ê¸‰ í‘œì‹œ ---
    history_data = load_channel_history()

    st.markdown("---")
    col_save, col_grade = st.columns([1, 4])
    
    with col_save:
        save_button = st.button("ğŸ’¾ ì´ ì±„ë„ íˆìŠ¤í† ë¦¬ì— ì €ì¥", type="secondary")

    if save_button:
        summary_data = get_channel_summary_row(info, df)
        if summary_data:
            history_data[channel_id] = summary_data
            save_channel_history(history_data)
            st.success(f"âœ… ì±„ë„ '{info['title']}' ì •ë³´ê°€ íˆìŠ¤í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            st.warning("ì €ì¥í•  ìµœê·¼ ì˜ìƒ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    # 1. ì±„ë„ í—¤ë” (ì¸ë„¤ì¼ + ê¸°ë³¸ ì •ë³´)
    st.markdown("---")
    c1, c2 = st.columns([1, 4])
    with c1:
        if info.get("thumbnail_url"):
            st.image(info["thumbnail_url"], caption="ì±„ë„ ì¸ë„¤ì¼", use_column_width=True)
    with c2:
        st.markdown(f"## ğŸ“º {info['title']}")
        grade = assign_channel_grade(info, df)
        st.caption(f"**ID**: {info['channel_id']} | **ê°œì„¤ì¼**: {info['published_at'].strftime('%Yë…„ %mì›” %dì¼')} | **ì±„ë„ ë“±ê¸‰**: â­ **{grade}**")
        st.markdown(info.get("description", "")[:250].replace('\n', ' ') + "...")

    st.markdown("---")
    
    # 2. KPI ì¹´ë“œ
    render_channel_kpi_cards(info, df)

    st.markdown("---")

    # 3. ì¸ì‚¬ì´íŠ¸ ë° íŒ¨í„´ ë¶„ì„
    st.subheader("ğŸ§  ì±„ë„ ìš´ì˜ ì¸ì‚¬ì´íŠ¸ (ë£° ê¸°ë°˜ ìš”ì•½)")
    st.info(make_simple_summary_for_channel(df))
    
    st.markdown("---")

    render_top_thumbnails(df)
    render_pattern_charts(df)
    render_keyword_suggestions(df)
    render_video_table(df)


def page_channel_history():
    """UPGRADE: 3ë‹¨ê³„ - íˆìŠ¤í† ë¦¬ ì €ì¥ ì±„ë„ ëª©ë¡ì„ ë³´ì—¬ì£¼ëŠ” í˜ì´ì§€"""
    st.title("ğŸ“š ì±„ë„ íˆìŠ¤í† ë¦¬ ë° ë¹„êµ ë¶„ì„")
    st.markdown("##### ì €ì¥ëœ ì±„ë„ë“¤ì„ í™•ì¸í•˜ê³  í•µì‹¬ ì§€í‘œë¥¼ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤.")
    
    history_data = load_channel_history()
    
    if not history_data:
        st.info("ì €ì¥ëœ ì±„ë„ íˆìŠ¤í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. 'íŠ¹ì • ì±„ë„ ì‹¬ì¸µ ë¶„ì„' í˜ì´ì§€ì—ì„œ ì±„ë„ì„ ë¶„ì„í•˜ê³  ì €ì¥í•´ ë³´ì„¸ìš”.")
        return

    history_list = list(history_data.values())
    df_history = pd.DataFrame(history_list)

    show_cols = [
        "title", "grade", "subscriber_count", "total_views", 
        "recent_avg_views", "recent_avg_daily_views", "videos_last_30d", "analysis_date"
    ]
    rename = {
        "title": "ì±„ë„ëª…", "grade": "ë“±ê¸‰", "subscriber_count": "êµ¬ë…ì ìˆ˜",
        "total_views": "ì´ ì¡°íšŒìˆ˜", "recent_avg_views": "ìµœê·¼ ì˜ìƒ í‰ê·  ì¡°íšŒìˆ˜",
        "recent_avg_daily_views": "ìµœê·¼ ì˜ìƒ ì¼ í‰ê·  ì¡°íšŒìˆ˜", "videos_last_30d": "ìµœê·¼ 30ì¼ ì˜ìƒ ìˆ˜",
        "analysis_date": "ë¶„ì„ì¼",
    }
    
    st.subheader("ğŸ ì €ì¥ëœ ì±„ë„ ìš”ì•½ í…Œì´ë¸”")
    st.dataframe(
        df_history[show_cols].rename(columns=rename).sort_values("subscriber_count", ascending=False),
        use_container_width=True, hide_index=True
    )

    st.subheader("ğŸ“ˆ ì±„ë„ë³„ í•µì‹¬ ì§€í‘œ ë¹„êµ")
    
    c1, c2 = st.columns(2)
    with c1:
        st.markdown("**êµ¬ë…ì ìˆ˜**")
        st.bar_chart(df_history.set_index("title")["subscriber_count"])

    with c2:
        st.markdown("**ìµœê·¼ ì˜ìƒ í‰ê·  ì¡°íšŒìˆ˜**")
        st.bar_chart(df_history.set_index("title")["recent_avg_views"])
        
    st.markdown("---")
    
    if st.button("ğŸ—‘ï¸ ì €ì¥ëœ íˆìŠ¤í† ë¦¬ ì „ì²´ ì‚­ì œ", type="danger"):
        save_channel_history({})
        st.success("âœ… ì±„ë„ íˆìŠ¤í† ë¦¬ê°€ ëª¨ë‘ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•©ë‹ˆë‹¤.")
        st.rerun()


def page_competitive_channels(api_key: str, video_limit: int):
    """UPGRADE: 5ë‹¨ê³„ - íˆìŠ¤í† ë¦¬ ê¸°ë°˜ìœ¼ë¡œ ê²½ìŸ ì±„ë„ì„ ì„ íƒí•˜ê³  ë²¤ì¹˜ë§ˆí‚¹"""
    st.title("ğŸ¯ ê²½ìŸ ì±„ë„ ë²¤ì¹˜ë§ˆí‚¹")
    st.markdown("##### íˆìŠ¤í† ë¦¬ì— ì €ì¥ëœ ì±„ë„ë“¤ì„ ë¹„êµí•˜ì—¬ ë²¤ì¹˜ë§ˆí‚¹í•©ë‹ˆë‹¤.")

    history_data = load_channel_history()
    
    if not history_data:
        st.info("ë¹„êµí•  ì±„ë„ì´ ì—†ìŠµë‹ˆë‹¤. 'íŠ¹ì • ì±„ë„ ì‹¬ì¸µ ë¶„ì„' í˜ì´ì§€ì—ì„œ ì±„ë„ì„ ë¶„ì„í•˜ê³  ì €ì¥í•´ ì£¼ì„¸ìš”.")
        return

    channel_options = {
        data['title']: data['channel_id']
        for data in history_data.values()
    }
    
    selected_titles = st.multiselect(
        "ğŸ” ë¹„êµí•  ì±„ë„ì„ ì„ íƒí•˜ì„¸ìš” (ìµœì†Œ 2ê°œ)",
        options=list(channel_options.keys()),
        default=list(channel_options.keys())[:2],
        key="comp_select"
    )

    if len(selected_titles) < 2:
        st.warning("ë¹„êµ ë¶„ì„ì„ ìœ„í•´ ìµœì†Œ 2ê°œ ì´ìƒì˜ ì±„ë„ì„ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")
        return

    selected_ids = [channel_options[title] for title in selected_titles]

    if st.button("ğŸ“Š ê²½ìŸ ì±„ë„ ë¹„êµ ì‹¤í–‰", type="primary"):
        rows = []
        error_channels = []

        for title, cid in zip(selected_titles, selected_ids):
            try:
                with st.spinner(f"ì±„ë„ '{title}' ë¶„ì„ ì¤‘..."):
                    info = fetch_channel_basic(api_key, cid)
                    df = fetch_channel_recent_videos(api_key, cid, video_limit)
            except HttpError as e:
                msg = str(e)
                if "quotaExceeded" in msg:
                    st.error("âŒ YouTube API ì¼ì¼ í• ë‹¹ëŸ‰ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë” ì´ìƒ ì±„ë„ì„ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); return
                else:
                    error_channels.append(f"{title} (ID: {cid}, ì˜¤ë¥˜: {msg})"); continue

            if not info or df.empty:
                error_channels.append(f"{title} (ID: {cid}, ë°ì´í„° ë¶€ì¡±)"); continue

            row = {
                "ì±„ë„ëª…": info["title"], "ì±„ë„ID": info["channel_id"],
                "êµ¬ë…ì ìˆ˜": info["subscriber_count"], "ì´ ì¡°íšŒìˆ˜": info["view_count"], "ì´ ì—…ë¡œë“œ ìˆ˜": info["video_count"],
                "ìµœê·¼ ì˜ìƒ ìˆ˜(ë¶„ì„)": len(df), 
                "ìµœê·¼ í‰ê·  ì¡°íšŒìˆ˜": int(df["views"].mean()),
                "ìµœê·¼ ì¤‘ì•™ê°’ ì¡°íšŒìˆ˜": int(df["views"].median()), 
                "ìµœê·¼ ìµœê³  ì¡°íšŒìˆ˜": int(df["views"].max()),
                "ìµœê·¼ í‰ê·  ê¸¸ì´(ë¶„)": round(df["duration_min"].mean(), 1),
                "ìµœê·¼ ì¼ í‰ê·  ì¡°íšŒìˆ˜(í‰ê· )": int(df["views_per_day"].mean()),
            }
            rows.append(row)

        if not rows:
            st.error("ì„±ê³µì ìœ¼ë¡œ ë¶„ì„ëœ ì±„ë„ì´ ì—†ìŠµë‹ˆë‹¤.")
            if error_channels: st.write("ì˜¤ë¥˜ ì±„ë„ ëª©ë¡:"); st.write("\n".join(error_channels))
            return

        result_df = pd.DataFrame(rows)
        
        st.subheader("ğŸ ê²½ìŸ ì±„ë„ ìš”ì•½ ë¹„êµ í…Œì´ë¸”")
        st.dataframe(result_df, use_container_width=True, hide_index=True)

        st.subheader("ğŸ“ˆ ì±„ë„ë³„ ìµœê·¼ í‰ê·  ì¡°íšŒìˆ˜ ë¹„êµ")
        st.bar_chart(result_df.set_index("ì±„ë„ëª…")["ìµœê·¼ í‰ê·  ì¡°íšŒìˆ˜"])

        st.subheader("ğŸ“ˆ ì±„ë„ë³„ ìµœê·¼ ì¼ í‰ê·  ì¡°íšŒìˆ˜(ì˜ìƒ 1ê°œ ê¸°ì¤€) ë¹„êµ")
        st.bar_chart(result_df.set_index("ì±„ë„ëª…")["ìµœê·¼ ì¼ í‰ê·  ì¡°íšŒìˆ˜(í‰ê· )"])

        if error_channels:
            with st.expander("âš  ë¶„ì„ ì‹¤íŒ¨/ë°ì´í„° ë¶€ì¡± ì±„ë„ ë³´ê¸°"):
                st.write("\n".join(error_channels))


# ----------------------------
# ë©”ì¸
# ----------------------------

def main():
    api_key = get_api_key()
    if not api_key: st.stop()

    st.sidebar.header("ğŸ” ë¶„ì„ ëª¨ë“œ ì„ íƒ")

    mode = st.sidebar.radio(
        "ë¶„ì„ ëŒ€ìƒ",
        ["íŠ¹ì • ì±„ë„ ì‹¬ì¸µ ë¶„ì„", "ì±„ë„ íˆìŠ¤í† ë¦¬ ë° ë¹„êµ ë¶„ì„", "í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¶„ì„", "ê²½ìŸ ì±„ë„ ë²¤ì¹˜ë§ˆí‚¹"], 
        index=0,
    )

    st.sidebar.markdown("---")
    video_limit = st.sidebar.slider(
        "ê°€ì ¸ì˜¬ ì˜ìƒ ê°œìˆ˜ (1íšŒ ë¶„ì„ë‹¹)",
        min_value=5, max_value=30, value=10,
        help="ê°’ì´ í´ìˆ˜ë¡ ë¶„ì„ì€ í’ë¶€í•´ì§€ì§€ë§Œ, YouTube API ì¼ì¼ í• ë‹¹ëŸ‰ì´ ë” ë¹¨ë¦¬ ì†Œëª¨ë©ë‹ˆë‹¤. 5~15 ê¶Œì¥.",
    )

    st.sidebar.markdown("---")
    st.sidebar.markdown(
        """
        ### ğŸš¨ API ì¿¼í„° ì ˆì•½ ê°€ì´ë“œ
        - **ì¶”ì²œê°’ ìœ ì§€**: ì˜ìƒ ê°œìˆ˜ëŠ” **5~15ê°œ** ì •ë„ë¡œ ìœ ì§€í•˜ì„¸ìš”.
        - **ìºì‹œ í™œìš©**: ë™ì¼í•œ ì±„ë„/í‚¤ì›Œë“œëŠ” 1ì‹œê°„ ë™ì•ˆ APIë¥¼ ì¬ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        - **ì´ˆê³¼ ì‹œ**: ì¿¼í„°ëŠ” ë§¤ì¼ ìë™ìœ¼ë¡œ ì´ˆê¸°í™”ë©ë‹ˆë‹¤.
        """
    )
    
    st.markdown("---")

    if mode == "í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¶„ì„":
        page_keyword_trend(api_key, video_limit)
    elif mode == "íŠ¹ì • ì±„ë„ ì‹¬ì¸µ ë¶„ì„":
        page_single_channel(api_key, video_limit)
    elif mode == "ì±„ë„ íˆìŠ¤í† ë¦¬ ë° ë¹„êµ ë¶„ì„": 
        page_channel_history()
    elif mode == "ê²½ìŸ ì±„ë„ ë²¤ì¹˜ë§ˆí‚¹":
        page_competitive_channels(api_key, video_limit)


if __name__ == "__main__":
    main()
